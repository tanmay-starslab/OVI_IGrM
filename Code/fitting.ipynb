{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# %%\n",
    "import yt\n",
    "import trident\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy\n",
    "from astropy.table import Table, join, vstack\n",
    "import os\n",
    "import time\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from matplotlib.ticker import MultipleLocator, FormatStrFormatter, MaxNLocator, FixedLocator\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import pygad as pg\n",
    "from trident import LSF\n",
    "import h5py\n",
    "\n",
    "# %%\n",
    "import matplotlib.pyplot as plt\n",
    "print(plt.colormaps())\n",
    "\n",
    "# %%\n",
    "simba_data_path = '/Users/tsingh65/ASU Dropbox/Tanmay Singh/Grad School/MgII_TNG_Project/Primary Project/Trident Codes/SIMBA_IGrM/revised_final/spectra_Simba100_z0.1_n300d2-sample_localized_COS-G130M_OVI_combined.hdf5'\n",
    "\n",
    "tng_data_path = '/Users/tsingh65/ASU Dropbox/Tanmay Singh/Grad School/MgII_TNG_Project/Primary Project/Trident Codes/TNG_50_z_0.1_groups/revised_final/spectra_TNG50-1_z0.1_n300d2-sample_localized_COS-G130M_OVI_combined.hdf5'\n",
    "\n",
    "tng_file_0 = '/Users/tsingh65/ASU Dropbox/Tanmay Singh/Grad School/MgII_TNG_Project/Primary Project/Trident Codes/TNG_50_z_0.1_groups/revised_final/spectra_TNG50-1_z0.1_n300d2-sample_localized_COS-G130M_OVI_0-of-14.hdf5'\n",
    "\n",
    "# %%\n",
    "# load the keys of the hdf5 file\n",
    "f = h5py.File(simba_data_path, 'r')\n",
    "keys = list(f.keys())\n",
    "print(keys)\n",
    "\n",
    "# %%\n",
    "# print the shpae of all the keys \n",
    "for key in keys:\n",
    "    print(f'{key} : {f[key].shape}')\n",
    "    \n",
    "\n",
    "# %%\n",
    "# load the largest EW_OVI_1031 value\n",
    "EW_OVI_1031 = f['EW_OVI_1031']\n",
    "EW_OVI_1031 = np.array(EW_OVI_1031)\n",
    "print(EW_OVI_1031.shape)\n",
    "print(np.max(EW_OVI_1031))\n",
    "\n",
    "# %%\n",
    "# Open HDF5 file\n",
    "with h5py.File(tng_data_path, 'r') as f:\n",
    "    # Fetch only the required equivalent width data (first group: indices 0:90000)\n",
    "    chunk_size = 10000  # Chunk size for processing\n",
    "    data_indices = range(0, 90000)  # Range for the first group\n",
    "    eq_widths = []\n",
    "    eq_width_indices = []\n",
    "\n",
    "    # Process in chunks to find the 100th maximum\n",
    "    for start in range(data_indices.start, data_indices.stop, chunk_size):\n",
    "        end = min(start + chunk_size, data_indices.stop)\n",
    "        chunk = f['EW_OVI_1031'][start:end]\n",
    "        eq_widths.extend(chunk)\n",
    "        eq_width_indices.extend(range(start, end))\n",
    "\n",
    "    # Convert to numpy arrays for sorting\n",
    "    eq_widths = np.array(eq_widths)\n",
    "    eq_width_indices = np.array(eq_width_indices)\n",
    "\n",
    "    # Find the 100th maximum equivalent width and its index\n",
    "    sorted_indices = np.argsort(eq_widths)[::-1]  # Sort in descending order\n",
    "    target_index_in_chunk = sorted_indices[50]  # 100th maximum (0-based index)\n",
    "    target_index = eq_width_indices[target_index_in_chunk]\n",
    "\n",
    "    print(f\"100th maximum EW_OVI_1031 value: {eq_widths[target_index_in_chunk]}\")\n",
    "    print(f\"Index of the 100th maximum EW_OVI_1031 in the dataset: {target_index}\")\n",
    "\n",
    "    # Fetch all information for the identified index\n",
    "    result = {\n",
    "        'EW_OVI_1031': f['EW_OVI_1031'][target_index],\n",
    "        'EW_OVI_1037': f['EW_OVI_1037'][target_index],\n",
    "        'flux': f['flux'][target_index, :],\n",
    "        'ray_dir': f['ray_dir'][:],  # ray_dir is not indexed\n",
    "        'ray_pos': f['ray_pos'][target_index, :],\n",
    "        'ray_total_dl': f['ray_total_dl'][()],  # Scalar value\n",
    "        'tau_OVI_1031': f['tau_OVI_1031'][target_index, :],\n",
    "        'tau_OVI_1037': f['tau_OVI_1037'][target_index, :],\n",
    "        'wave': f['wave'][:]\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "# Save the result dictionary\n",
    "print(\"Data fetched successfully. Example:\", result)\n",
    "\n",
    "# Plot flux with respect to wave\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(result['wave'], result['flux'], label='Flux')\n",
    "plt.xlabel('Wavelength')\n",
    "plt.ylabel('Flux')\n",
    "plt.title('Flux vs. Wavelength')\n",
    "plt.legend()\n",
    "plt.xlim(1030*(1+z),1042*(1+z))\n",
    "#plt.xlim(1170,1190)\n",
    "plt.grid()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Calculate flux from tau and plot it with tau\n",
    "flux_from_tau = np.exp(-result['tau_OVI_1031'])\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(result['wave'], flux_from_tau, label='Flux (from Tau)')\n",
    "plt.xlabel('Wavelength')\n",
    "plt.ylabel('Flux (from Tau)')\n",
    "plt.title('Flux (from Tau) vs. Wavelength')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "#plt.xlim(1120,1160)\n",
    "plt.xlim(1030*(1+z),1035*(1+z))\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "# save the flux_from_tau = np.exp(-result['tau_OVI_1031']) and result['wave'] to a h5 file\n",
    "with h5py.File('flux_from_tau.h5', 'w') as f:\n",
    "    f.create_dataset('flux', data=flux_from_tau)\n",
    "    f.create_dataset('wavelength', data=result['wave'])\n",
    "    f.create_dataset('tau', data=result['tau_OVI_1031'])\n",
    "    \n",
    "\n",
    "# %%\n",
    "sg = trident.load_spectrum('flux_from_tau.h5')\n",
    "\n",
    "# %%\n",
    "wavelength_old = sg.lambda_field\n",
    "flux_old = sg.flux_field\n",
    "\n",
    "\n",
    "# %%\n",
    "sg.apply_lsf(filename='COS_G130M_1150.txt')\n",
    "wavelength_new = sg.lambda_field\n",
    "flux_new = sg.flux_field\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "# plot the flux before and after applying the LSF\n",
    "z = 0.09940180263022191\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(wavelength_old, flux_old, label='Flux (before LSF)')\n",
    "plt.plot(wavelength_new, flux_new, label='Flux (after LSF)')\n",
    "plt.xlabel('Wavelength')\n",
    "plt.ylabel('Flux')\n",
    "plt.title('Flux vs. Wavelength')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlim(1030*(1+z), 1035*(1+z))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# %%\n",
    "sg.add_gaussian_noise(20)\n",
    "\n",
    "# %%\n",
    "wavelength_obs = sg.lambda_field.value\n",
    "flux = sg.flux_field \n",
    "flux_err = np.ones_like(flux) * 0.1  # Assume a constant error for now\n",
    "\n",
    "# Constants\n",
    "rest_wavelength = 1031.926  # OVI rest wavelength in Å\n",
    "#z =  0.137807                 # Previously used redshift\n",
    "z = 0.09940180263022191\n",
    "observed_rest_wavelength = rest_wavelength * (1 + z)  # Adjusted rest wavelength\n",
    "c = 299792.458             # Speed of light in km/s\n",
    "\n",
    "# Convert to velocity space\n",
    "velocity = c * (wavelength_obs - observed_rest_wavelength) / observed_rest_wavelength\n",
    "zoom_mask = (velocity >= -800) & (velocity <= 800)\n",
    "velocity_zoom = velocity[zoom_mask]\n",
    "flux_zoom = flux[zoom_mask]\n",
    "flux_err_zoom = flux_err[zoom_mask]\n",
    "\n",
    "# Calculate the bounds for the shaded region\n",
    "flux_upper = flux_zoom + flux_err_zoom\n",
    "flux_lower = flux_zoom - flux_err_zoom\n",
    "\n",
    "# Plot the zoomed-in region in velocity space\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create a stepped plot using ax.step\n",
    "ax.step(velocity_zoom, flux_zoom, where='mid', label='Flux', color='blue', linewidth=1.5)\n",
    "\n",
    "# Add the shaded error region\n",
    "ax.fill_between(velocity_zoom, flux_lower, flux_upper, color='green', alpha=0.3, label='Error')\n",
    "\n",
    "# Add vertical and horizontal lines for reference\n",
    "ax.axvline(x=0, color='red', linestyle='--', label=f'OVI {rest_wavelength} Å (0 km/s)', linewidth=2)\n",
    "ax.axhline(y=1, color='gray', linestyle='--', label='Continuum')\n",
    "\n",
    "# # Set x-axis formatter to display floating-point numbers\n",
    "# formatter = FuncFormatter(lambda x, _: f'{x:.0f}')\n",
    "# ax.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "# Set plot labels and title\n",
    "ax.set_xlabel('Velocity (km/s)', fontsize=14)\n",
    "ax.set_ylabel('Normalized Flux', fontsize=14)\n",
    "# ax.set_xlim(-500, 500)\n",
    "ax.set_ylim(0.1, 1.35)\n",
    "\n",
    "# Customize ticks and grid\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add legend\n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "# Save and show the plot\n",
    "#plt.savefig('OVI_velocity_space_zoom_shaded_z_013748.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "def shift_to_restframe(wave,z):\n",
    "    rest = wave / (1 + z)\n",
    "    return rest\n",
    "\n",
    "def wave_to_vel(wavelength,center_wave):\n",
    "    vel = 2.99792458e5 * ((wavelength/center_wave) - 1)\n",
    "    return vel \n",
    "\n",
    "def vel_to_wave(vel,center_wave):\n",
    "    wave = (1. + (vel/2.99792458e5)) * center_wave\n",
    "    return wave\n",
    "\n",
    "def match_ion(line):\n",
    "    if line == 'H I 1216':\n",
    "        ion = 'H1215'\n",
    "        return ion\n",
    "    elif line == 'H I 1026':\n",
    "        ion = 'H1025'\n",
    "        return ion\n",
    "    elif line == 'Ly c':\n",
    "        ion = 'H972'\n",
    "        return ion\n",
    "    elif line == 'O VI 1032':\n",
    "        ion = 'OVI1031'\n",
    "        return ion\n",
    "    elif line == 'O VI 1038':\n",
    "        ion = 'OVI1037'\n",
    "        return ion\n",
    "    elif line == 'Si II 1193':\n",
    "        ion = 'SiII1193'\n",
    "        return ion\n",
    "    elif line == 'Si II 1190':\n",
    "        ion = 'SiII1190'\n",
    "        return ion\n",
    "    elif line == 'Si III 1206':\n",
    "        ion = 'SiIII1206'\n",
    "        return ion\n",
    "    elif line == 'N V 1239':\n",
    "        ion = 'NV1238'\n",
    "        return ion\n",
    "    elif line == 'C II 1036':\n",
    "        ion = 'CII1036'\n",
    "        return ion\n",
    "    else:\n",
    "        print('Error: Check to make sure Trident ion matches Pygad')\n",
    "\n",
    "def test_for_saturation(strong_line, flux, z):\n",
    "    if strong_line == 'H I 1216':\n",
    "        if np.min(flux) <= 0.05:\n",
    "            use_line = 'H I 1026'\n",
    "            saturated = True\n",
    "        else:\n",
    "            use_line = strong_line\n",
    "            saturated = False\n",
    "    elif strong_line == 'H I 1026':\n",
    "        if np.min(flux) <= 0.25:\n",
    "            use_line = 'H I 972'\n",
    "            saturated = True\n",
    "        else:\n",
    "            use_line = strong_line\n",
    "            saturated = False\n",
    "    elif strong_line == 'O VI 1032':\n",
    "        if np.min(flux) <= 0.25:\n",
    "            use_line = 'O VI 1038'\n",
    "            saturated = True\n",
    "        else:\n",
    "            use_line = strong_line\n",
    "            saturated = False\n",
    "    elif strong_line == 'Si II 1193':\n",
    "        if np.min(flux) <= 0.25:\n",
    "            use_line = 'Si II 1190'\n",
    "            saturated = True\n",
    "        else:\n",
    "            use_line = strong_line\n",
    "            saturated = False\n",
    "    else:\n",
    "        use_line = strong_line\n",
    "        saturated = False\n",
    "    return saturated, use_line\n",
    "\n",
    "def EW_to_N(pg_ion,ew_err):\n",
    "\n",
    "    ## Following Draine eq. 9.15\n",
    "\n",
    "    f = float(pg.analysis.absorption_spectra.lines[pg_ion]['f'])\n",
    "    l = float(pg.analysis.absorption_spectra.lines[pg_ion]['l'].split()[0])\n",
    "    N = 1.13e12 * (1 * ew_err * 1.0e-11) / f / (l * 1.0e-8)**2\n",
    "\n",
    "    return np.log10(N)\n",
    "\n",
    "def N_to_EW(pg_ion,logN):\n",
    "    \n",
    "    ## Following Draine eq. 9.15\n",
    "\n",
    "    f = float(pg.analysis.absorption_spectra.lines[pg_ion]['f'])\n",
    "    l = float(pg.analysis.absorption_spectra.lines[pg_ion]['l'].split()[0])\n",
    "    EW = f * (l * 1.0e-8)**2 * 10**(logN) / 1.13e12\n",
    "\n",
    "    return EW\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fit_vp_pipeline(ray, ion, wave, vel, flux, error, z, logN_bounds=[11, 19], b_bounds=[5, 200], min_region_width=5, N_sigma=1.5):\n",
    "    \"\"\"\n",
    "    Fits Voigt profiles to absorption regions and generates a table of results.\n",
    "\n",
    "    Parameters:\n",
    "    - ray: Sightline ID\n",
    "    - ion: Ion name\n",
    "    - wave: Wavelength array\n",
    "    - vel: Velocity array\n",
    "    - flux: Flux array\n",
    "    - error: Error array\n",
    "    - z: Redshift\n",
    "    - logN_bounds: Logarithmic column density bounds for the fit\n",
    "    - b_bounds: Doppler parameter bounds for the fit\n",
    "    - min_region_width: Minimum width of the region to consider for fitting (in pixels)\n",
    "    - N_sigma: Detection threshold in sigma for the region\n",
    "\n",
    "    Returns:\n",
    "    - sat_flag: Boolean indicating if the line is saturated\n",
    "    - t: Astropy Table containing fitting results\n",
    "    \"\"\"\n",
    "    wave_subset = wave[(vel >= -1500) & (vel <= 1500)]\n",
    "    flux_subset = flux[(vel >= -1500) & (vel <= 1500)]\n",
    "    error_subset = error[(vel >= -1500) & (vel <= 1500)]\n",
    "\n",
    "    sat_flag = False\n",
    "    if np.min(flux) <= 0.2:\n",
    "        sat_flag = True\n",
    "\n",
    "    # Creating output table\n",
    "    t = Table(names=('Sightline', 'Species', 'EW(mA)', 'dEW(mA)', 'N', 'dN', 'b', 'db', 'v', 'dv', 'l', 'dl', 'UpLim', 'Sat', 'Chisq'),\n",
    "              dtype=['i4', 'S10', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'bool', 'bool', 'f8'])\n",
    "\n",
    "    # Detect absorption regions\n",
    "    regions, _ = pg.analysis.vpfit.find_regions(\n",
    "        wave_subset, flux_subset, error_subset, min_region_width=min_region_width, N_sigma=N_sigma, extend=True)\n",
    "    print(f'Found {len(regions)} absorption regions for {ion}')\n",
    "\n",
    "    if len(regions) > 0:\n",
    "        # Fit detected regions\n",
    "        fit = pg.analysis.vpfit.fit_profiles(\n",
    "            ion, wave_subset, flux_subset, error_subset,\n",
    "            chisq_lim=1, max_lines=6, mode=\"Voigt\",\n",
    "            logN_bounds=logN_bounds, b_bounds=b_bounds,\n",
    "            min_region_width=min_region_width, N_sigma=N_sigma, extend=True\n",
    "        )\n",
    "        print(fit)\n",
    "        chisq = fit['chisq']\n",
    "        vels = wave_to_vel(fit['l'], float(pg.analysis.absorption_spectra.lines[pg_ion]['l'].split()[0]))\n",
    "\n",
    "        for v in vels:\n",
    "            for j in range(len(fit['EW'])):  # Loop over components\n",
    "                t.add_row((\n",
    "                    ray,\n",
    "                    ion.replace(' ', ''),\n",
    "                    fit['EW'][j] * 1000,  # EW in mA for the j-th component\n",
    "                    np.nan,  # Placeholder for dEW\n",
    "                    fit['N'][j],\n",
    "                    fit['dN'][j],\n",
    "                    fit['b'][j],\n",
    "                    fit['db'][j],\n",
    "                    wave_to_vel(fit['l'][j], float(pg.analysis.absorption_spectra.lines[pg_ion]['l'].split()[0])),\n",
    "                    (wave_to_vel(fit['l'][j] + fit['dl'][j], float(pg.analysis.absorption_spectra.lines[pg_ion]['l'].split()[0]))\n",
    "                    - wave_to_vel(fit['l'][j], float(pg.analysis.absorption_spectra.lines[pg_ion]['l'].split()[0]))) / 2.0,\n",
    "                    fit['l'][j],\n",
    "                    fit['dl'][j],\n",
    "                    False,  # Not an upper limit\n",
    "                    sat_flag,\n",
    "                    fit['chisq'][j]  # Assign chisq per component\n",
    "                ))\n",
    "\n",
    "    else:\n",
    "        # No detected regions: Calculate upper limit\n",
    "        vel_subset = wave_to_vel(wave_subset, float(pg.analysis.absorption_spectra.lines[pg_ion]['l'].split()[0]))\n",
    "        wave_pm100 = wave_subset[(vel_subset >= -50.0) & (vel_subset <= 50.0)]\n",
    "        flux_pm100 = flux_subset[(vel_subset >= -50.0) & (vel_subset <= 50.0)]\n",
    "        error_pm100 = error_subset[(vel_subset >= -50.0) & (vel_subset <= 50.0)]\n",
    "        ew_pm100 = pg.analysis.vpfit.EquivalentWidth(flux_pm100, wave_pm100) * 1000  # mA\n",
    "        print(f'EW: {ew_pm100}')\n",
    "        print(f'error_pm100: {error_pm100}')\n",
    "        print(f'abs(wave_pm100[1] - wave_pm100[0])= {abs(wave_pm100[1] - wave_pm100[0])}')\n",
    "        dew_pm100 = ((np.sqrt(np.sum(error_pm100**2))) * abs(wave_pm100[1] - wave_pm100[0])) * 1000  # mA\n",
    "        print(f'dEW: {dew_pm100}')\n",
    "        N_lim = EW_to_N(pg_ion, dew_pm100)\n",
    "\n",
    "        # Add a single row for the non-detection case\n",
    "        t.add_row((\n",
    "            ray,\n",
    "            ion.replace(' ', ''),\n",
    "            ew_pm100,  # EW in mA\n",
    "            dew_pm100,  # dEW in mA\n",
    "            N_lim,\n",
    "            np.nan,  # dN placeholder\n",
    "            np.nan,  # b placeholder\n",
    "            np.nan,  # db placeholder\n",
    "            0,  # velocity placeholder\n",
    "            50,  # dv placeholder\n",
    "            np.nan,  # wavelength placeholder\n",
    "            np.nan,  # dl placeholder\n",
    "            True,  # Upper limit\n",
    "            sat_flag,\n",
    "            np.nan  # chisq placeholder\n",
    "        ))\n",
    "\n",
    "    return sat_flag, t\n",
    "\n",
    "# %%\n",
    "EW_to_N('OVI1031',11.88)\n",
    "\n",
    "# %%\n",
    "def fit_vp_pipeline_new(ray, ion, wave, vel, flux, error, z, logN_bounds=[11, 19], b_bounds=[5, 200], min_region_width=5, N_sigma=1.5,chisq_lim=0.25):\n",
    "    \"\"\"\n",
    "    Fits Voigt profiles to absorption regions and generates a table of results.\n",
    "\n",
    "    Parameters:\n",
    "    - ray: Sightline ID\n",
    "    - ion: Ion name\n",
    "    - wave: Wavelength array\n",
    "    - vel: Velocity array\n",
    "    - flux: Flux array\n",
    "    - error: Error array\n",
    "    - z: Redshift\n",
    "    - logN_bounds: Logarithmic column density bounds for the fit\n",
    "    - b_bounds: Doppler parameter bounds for the fit\n",
    "    - min_region_width: Minimum width of the region to consider for fitting (in pixels)\n",
    "    - N_sigma: Detection threshold in sigma for the region\n",
    "\n",
    "    Returns:\n",
    "    - sat_flag: Boolean indicating if the line is saturated\n",
    "    - t: Astropy Table containing fitting results\n",
    "    \"\"\"\n",
    "    pg_ion = 'OVI1031'\n",
    "    # wave_subset = wave[(vel >= -1500) & (vel <= 1500)]\n",
    "    # flux_subset = flux[(vel >= -1500) & (vel <= 1500)]\n",
    "    # error_subset = error[(vel >= -1500) & (vel <= 1500)]\n",
    "    wave_subset = wave[(vel >= -800) & (vel <= 800)]\n",
    "    flux_subset = flux[(vel >= -800) & (vel <= 800)]\n",
    "    error_subset = error[(vel >= -800) & (vel <= 800)]\n",
    "\n",
    "    sat_flag = False\n",
    "    if np.min(flux) <= 0.2:\n",
    "        sat_flag = True\n",
    "\n",
    "    # Creating output table\n",
    "    t = Table(names=('Sightline', 'Species', 'EW(mA)', 'dEW(mA)', 'N', 'dN', 'b', 'db', 'v', 'dv', 'l', 'dl', 'UpLim', 'Sat', 'Chisq'),\n",
    "              dtype=['i4', 'S10', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'bool', 'bool', 'f8'])\n",
    "\n",
    "    # Detect absorption regions\n",
    "    regions, _ = pg.analysis.vpfit.find_regions(\n",
    "        wave_subset, flux_subset, error_subset, min_region_width=min_region_width, N_sigma=N_sigma, extend=True)\n",
    "    print(f'Found {len(regions)} absorption regions for {ion}')\n",
    "\n",
    "    if len(regions) > 0:\n",
    "        # Fit detected regions\n",
    "        fit = pg.analysis.vpfit.fit_profiles(\n",
    "            ion, wave_subset, flux_subset, error_subset,\n",
    "            chisq_lim=chisq_lim, max_lines=4, mode=\"Voigt\",\n",
    "            logN_bounds=logN_bounds, b_bounds=b_bounds,\n",
    "            min_region_width=min_region_width, N_sigma=N_sigma, extend=True\n",
    "        )\n",
    "        print(fit)\n",
    "        chisq = fit['chisq']\n",
    "        vels = wave_to_vel(fit['l'], float(pg.analysis.absorption_spectra.lines[pg_ion]['l'].split()[0]))\n",
    "\n",
    "        # for v in vels:\n",
    "        #     for j in range(len(fit['EW'])):  # Loop over components\n",
    "        #         t.add_row((\n",
    "        #             ray,\n",
    "        #             ion.replace(' ', ''),\n",
    "        #             fit['EW'][j] * 1000,  # EW in mA for the j-th component\n",
    "        #             np.nan,  # Placeholder for dEW\n",
    "        #             fit['N'][j],\n",
    "        #             fit['dN'][j],\n",
    "        #             fit['b'][j],\n",
    "        #             fit['db'][j],\n",
    "        #             wave_to_vel(fit['l'][j], float(pg.analysis.absorption_spectra.lines[pg_ion]['l'].split()[0])),\n",
    "        #             (wave_to_vel(fit['l'][j] + fit['dl'][j], float(pg.analysis.absorption_spectra.lines[pg_ion]['l'].split()[0]))\n",
    "        #             - wave_to_vel(fit['l'][j], float(pg.analysis.absorption_spectra.lines[pg_ion]['l'].split()[0]))) / 2.0,\n",
    "        #             fit['l'][j],\n",
    "        #             fit['dl'][j],\n",
    "        #             False,  # Not an upper limit\n",
    "        #             sat_flag,\n",
    "        #             fit['chisq'][j]  # Assign chisq per component\n",
    "        #         ))\n",
    "        for j in range(len(fit['EW'])):  # Loop over components\n",
    "            t.add_row((\n",
    "                ray,\n",
    "                ion.replace(' ', ''),\n",
    "                fit['EW'][j] * 1000,  # EW in mA for the j-th component\n",
    "                np.nan,  # Placeholder for dEW\n",
    "                fit['N'][j],\n",
    "                fit['dN'][j],\n",
    "                fit['b'][j],\n",
    "                fit['db'][j],\n",
    "                wave_to_vel(fit['l'][j], float(pg.analysis.absorption_spectra.lines[pg_ion]['l'].split()[0])),\n",
    "                (wave_to_vel(fit['l'][j] + fit['dl'][j], float(pg.analysis.absorption_spectra.lines[pg_ion]['l'].split()[0]))\n",
    "                - wave_to_vel(fit['l'][j], float(pg.analysis.absorption_spectra.lines[pg_ion]['l'].split()[0]))) / 2.0,\n",
    "                fit['l'][j],\n",
    "                fit['dl'][j],\n",
    "                False,  # Not an upper limit\n",
    "                sat_flag,\n",
    "                fit['chisq'][j]  # Assign chisq per component\n",
    "            ))\n",
    "\n",
    "    else:\n",
    "        fit = None\n",
    "        # No detected regions: Calculate upper limit\n",
    "        vel_subset = wave_to_vel(wave_subset, float(pg.analysis.absorption_spectra.lines[pg_ion]['l'].split()[0]))\n",
    "        wave_pm100 = wave_subset[(vel_subset >= -50.0) & (vel_subset <= 50.0)]\n",
    "        flux_pm100 = flux_subset[(vel_subset >= -50.0) & (vel_subset <= 50.0)]\n",
    "        error_pm100 = error_subset[(vel_subset >= -50.0) & (vel_subset <= 50.0)]\n",
    "        ew_pm100 = pg.analysis.vpfit.EquivalentWidth(flux_pm100, wave_pm100) * 1000  # mA\n",
    "        print(f'EW: {ew_pm100}')\n",
    "        print(f'error_pm100: {error_pm100}')\n",
    "        print(f'abs(wave_pm100[1] - wave_pm100[0])= {abs(wave_pm100[1] - wave_pm100[0])}')\n",
    "        dew_pm100 = ((np.sqrt(np.sum(error_pm100**2))) * abs(wave_pm100[1] - wave_pm100[0])) * 1000  # mA\n",
    "        print(f'dEW: {dew_pm100}')\n",
    "        N_lim = EW_to_N(pg_ion, dew_pm100)\n",
    "\n",
    "        # Add a single row for the non-detection case\n",
    "        t.add_row((\n",
    "            ray,\n",
    "            ion.replace(' ', ''),\n",
    "            ew_pm100,  # EW in mA\n",
    "            dew_pm100,  # dEW in mA\n",
    "            N_lim,\n",
    "            np.nan,  # dN placeholder\n",
    "            np.nan,  # b placeholder\n",
    "            np.nan,  # db placeholder\n",
    "            0,  # velocity placeholder\n",
    "            50,  # dv placeholder\n",
    "            np.nan,  # wavelength placeholder\n",
    "            np.nan,  # dl placeholder\n",
    "            True,  # Upper limit\n",
    "            sat_flag,\n",
    "            np.nan  # chisq placeholder\n",
    "        ))\n",
    "\n",
    "    return sat_flag, t,fit,regions\n",
    "\n",
    "results_table = Table(\n",
    "    names=(\n",
    "        'Sightline', 'Species', 'EW(mA)', 'dEW(mA)', 'N', 'dN', 'b', 'db', 'v', \n",
    "        'dv', 'l', 'dl', 'UpLim', 'Sat', 'Chisq'\n",
    "    ),\n",
    "    dtype=['i4', 'S10', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'bool', 'bool', 'f8']\n",
    ")\n",
    "\n",
    "line_list = ['O VI 1032']\n",
    "\n",
    "# %%\n",
    "results_table = Table(\n",
    "    names=(\n",
    "        'Sightline', 'Species', 'EW(mA)', 'dEW(mA)', 'N', 'dN', 'b', 'db', 'v', \n",
    "        'dv', 'l', 'dl', 'UpLim', 'Sat', 'Chisq'\n",
    "    ),\n",
    "    dtype=['i4', 'S10', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'bool', 'bool', 'f8']\n",
    ")\n",
    "\n",
    "line_list = ['O VI 1032']\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "try:\n",
    "\n",
    "    sg.apply_lsf(filename='COS_G130M_1150.txt')\n",
    "    sg.add_gaussian_noise(20)\n",
    "\n",
    "\n",
    "    pg_ion = 'OVI1031'\n",
    "    wave_binned = np.arange(sg.lambda_min.value, sg.lambda_max.value, 0.0112)\n",
    "    flux_binned = np.interp(wave_binned, sg.lambda_field.value, sg.flux_field)\n",
    "    #error_binned = np.interp(wave_binned, sg.lambda_field.value, sg.error_func(sg.flux_field))\n",
    "    error_binned = np.interp(wave_binned, sg.lambda_field.value, flux_err)\n",
    "    print(f\"Error Binned is {error_binned}\")\n",
    "    # change the error to 1 sigma (1/3)\n",
    "    # error_binned = error_binned *0.5\n",
    "    # print(f\"Error Binned is {error_binned}\")\n",
    "    wave_binned /= (1 + z)\n",
    "    vel_binned = wave_to_vel(wave_binned, float(pg.analysis.absorption_spectra.lines[pg_ion]['l'].split()[0]))\n",
    "\n",
    "    min_region_width = 3  # pixels\n",
    "    #N_sigma = 0.5  # 1-sigma detection limit\n",
    "    N_sigma = 1 # 1-sigma detection limit\n",
    "    logN_bounds = [12, 18]\n",
    "    b_bounds = [5, 200]\n",
    "\n",
    "    saturation_flag, output_table,fit = fit_vp_pipeline_new( 1, pg_ion, wave_binned, vel_binned, flux_binned, error_binned, z, logN_bounds, b_bounds, min_region_width, N_sigma)\n",
    "    results_table = vstack((results_table, output_table))\n",
    "\n",
    "except RuntimeError:\n",
    "    empty_row = Table(\n",
    "        [[ 1], [np.nan], [np.nan], [np.nan], [np.nan], [np.nan], [np.nan], [np.nan], [np.nan], [np.nan], [np.nan], [np.nan], [False], [np.nan], [np.nan]],)\n",
    "\n",
    "# # Save intermediate results every 50 iterations\n",
    "# if (i + 1) % 50 == 0:\n",
    "#     print(f\"Writing intermediate results after {i + 1} sightlines...\")\n",
    "#     results_table.write(\n",
    "#         os.path.join(data_path, f'Grp_{halo_ids[grp_index]}_fitting_results.txt'),\n",
    "#         format='ascii.fixed_width',\n",
    "#         overwrite=True\n",
    "#     )\n",
    "\n",
    "# # Final save for all results\n",
    "# print(\"Writing final results...\")\n",
    "# results_table.write(\n",
    "#     os.path.join(sol_result_path, 'local_run_6360.txt'),\n",
    "#     format='ascii.fixed_width',\n",
    "#     overwrite=True\n",
    "# )\n",
    "\n",
    "# %%\n",
    "fit\n",
    "\n",
    "# %%\n",
    "def generate_params(fitting_data):\n",
    "    \"\"\"\n",
    "    Generate the parameter array for Voigt profile fitting from the fitting_data dictionary.\n",
    "\n",
    "    Parameters:\n",
    "        fitting_data (dict): Dictionary containing 'N', 'b', and 'l' arrays.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Flattened parameter array in the required format.\n",
    "    \"\"\"\n",
    "    # Ensure 'N', 'b', and 'l' keys are present\n",
    "    if not all(key in fitting_data for key in ['N', 'b', 'l']):\n",
    "        raise ValueError(\"fitting_data must contain 'N', 'b', and 'l' keys.\")\n",
    "    \n",
    "    # Interleave 'N', 'b', and 'l' to create the params array\n",
    "    params = np.empty((3 * len(fitting_data['N'])))\n",
    "    params[0::3] = fitting_data['N']  # Column densities\n",
    "    params[1::3] = fitting_data['b']  # Doppler parameters\n",
    "    params[2::3] = fitting_data['l']  # Centroid wavelengths\n",
    "    \n",
    "    return params\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import h5py\n",
    "from scipy.constants import c as c_km_s  # Speed of light in km/s\n",
    "import pygad as pg\n",
    "\n",
    "# Constants\n",
    "rest_wavelength = 1031.926  # OVI rest wavelength in Å\n",
    "z = 0.09940180263022191                 # Redshift\n",
    "#z =  0.137807   \n",
    "c_km_s = c_km_s / 1e3       # Speed of light in km/s\n",
    "\n",
    "# Provided Data\n",
    "wavelength_obs = sg.lambda_field.value  # Observed wavelength from the previous code\n",
    "flux = sg.flux_field                    # Flux from the previous code\n",
    "flux_err = np.ones_like(flux) * 0.1    # Assume a constant flux error\n",
    "\n",
    "# Convert observed wavelength to rest frame\n",
    "wavelength_rest = wavelength_obs / (1 + z)\n",
    "\n",
    "# Select the range in rest wavelength space\n",
    "zoom_mask = (wavelength_rest >= 1030) & (wavelength_rest <= 1035)\n",
    "\n",
    "# Extract zoomed data in rest wavelength space\n",
    "wavelength_zoom_rest = wavelength_rest[zoom_mask]\n",
    "flux_zoom = flux[zoom_mask]\n",
    "flux_err_zoom = flux_err[zoom_mask]\n",
    "flux_upper = flux_zoom + flux_err_zoom\n",
    "flux_lower = flux_zoom - flux_err_zoom\n",
    "\n",
    "\n",
    "fitting_data = fit\n",
    "# Generate the Voigt profile for the fitted spectrum\n",
    "line_data = pg.analysis.absorption_spectra.lines['OVI1031']\n",
    "\n",
    "# Generate the params array dynamically\n",
    "params = generate_params(fitting_data)\n",
    "\n",
    "# Voigt profile computation remains the same\n",
    "line_data = pg.analysis.absorption_spectra.lines['OVI1031']\n",
    "wave_subset = wavelength_zoom_rest  # Use the zoomed rest wavelength range\n",
    "total_tau = pg.analysis.vpfit.model_tau(line_data, params, wave_subset, mode='Voigt')\n",
    "model_flux = np.exp(-total_tau)\n",
    "\n",
    "# Rest of the code for plotting, FWHM calculation, and annotations remains unchanged.\n",
    "\n",
    "# Compute velocity space\n",
    "observed_rest_wavelength = rest_wavelength * (1 + z)\n",
    "velocity = c_km_s * (wavelength_obs - observed_rest_wavelength) / observed_rest_wavelength\n",
    "\n",
    "# Zoom mask for velocity range (-800 km/s to +800 km/s)\n",
    "velocity_zoom = velocity[zoom_mask]\n",
    "\n",
    "# Calculate FWHM for each feature\n",
    "centroids = params[2::3]  # Extract every 3rd value starting from index 2\n",
    "doppler_params = params[1::3]  # Extract every 3rd value starting from index 1\n",
    "fwhms = [(2 * np.sqrt(np.log(2)) * b / c_km_s) * l for b, l in zip(doppler_params, centroids)]\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Original spectrum\n",
    "ax.plot(wavelength_zoom_rest, flux_zoom, label='Original Spectrum', color='blue')\n",
    "ax.fill_between(wavelength_zoom_rest, flux_lower, flux_upper, color='green', alpha=0.3, label='Error')\n",
    "\n",
    "# Fitted spectrum (Voigt profile)\n",
    "ax.step(wave_subset, model_flux, label='Fitted Spectrum (Voigt Profile)', color='red', where='mid', linewidth=3)\n",
    "\n",
    "# Highlight centroids and add FWHM arrows\n",
    "arrowprops = dict(arrowstyle='<->', color='black', lw=1.5)\n",
    "for i, (centroid, fwhm, b) in enumerate(zip(centroids, fwhms, doppler_params)):\n",
    "    ax.axvline(centroid, color=f'C{i}', linestyle='--', label=f'Centroid {i+1}: {centroid:.2f} Å', linewidth=2)\n",
    "    ax.annotate('', xy=(centroid - fwhm / 2, 0.75 - i * 0.05), \n",
    "                xytext=(centroid + fwhm / 2, 0.75 - i * 0.05), arrowprops=arrowprops)\n",
    "    ax.text(centroid, 0.77 - i * 0.05, f'b = {b:.1f} km/s', ha='center', fontsize=10)\n",
    "\n",
    "# Highlight reference line for OVI in rest wavelength\n",
    "ax.axvline(rest_wavelength, color='purple', linestyle='--', label=f'OVI {rest_wavelength:.2f} Å (Rest Frame)', linewidth=2)\n",
    "\n",
    "# Set labels, limits, and grid\n",
    "ax.set_xlabel('Rest Wavelength (Å)', fontsize=14)\n",
    "ax.set_ylabel('Normalized Flux', fontsize=14)\n",
    "ax.set_xlim(wavelength_zoom_rest.min(), wavelength_zoom_rest.max())\n",
    "ax.set_ylim(0.2, 1.35)\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "#ax.legend(fontsize=12)\n",
    "\n",
    "# Save and show the plot\n",
    "plt.savefig('OVI_Voigt_Profile_Fit_0.1_err.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.constants import c as c_km_s  # Speed of light in km/s\n",
    "import pygad as pg\n",
    "\n",
    "# Constants\n",
    "rest_wavelength = 1031.926  # OVI rest wavelength in Å\n",
    "z = 0.09940180263022191  # Redshift\n",
    "c_km_s = c_km_s / 1e3  # Speed of light in km/s\n",
    "\n",
    "# Provided Data\n",
    "wavelength_obs = sg.lambda_field.value  # Observed wavelength\n",
    "flux = sg.flux_field  # Flux\n",
    "flux_err = np.ones_like(flux) * 0.15  # Assume a constant flux error\n",
    "\n",
    "# Convert observed wavelength to rest frame\n",
    "wavelength_rest = wavelength_obs / (1 + z)\n",
    "\n",
    "# Select the range in rest wavelength space\n",
    "zoom_mask = (wavelength_rest >= 1030) & (wavelength_rest <= 1035)\n",
    "\n",
    "# Extract zoomed data in rest wavelength space\n",
    "wavelength_zoom_rest = wavelength_rest[zoom_mask]\n",
    "flux_zoom = flux[zoom_mask]\n",
    "flux_err_zoom = flux_err[zoom_mask]\n",
    "flux_upper = flux_zoom + flux_err_zoom\n",
    "flux_lower = flux_zoom - flux_err_zoom\n",
    "\n",
    "# Generate the Voigt profile for the fitted spectrum\n",
    "line_data = pg.analysis.absorption_spectra.lines['OVI1031']\n",
    "\n",
    "# Generate the params array dynamically\n",
    "params = generate_params(fitting_data)\n",
    "\n",
    "# Compute Voigt profile\n",
    "wave_subset = wavelength_zoom_rest  # Use the zoomed rest wavelength range\n",
    "total_tau = pg.analysis.vpfit.model_tau(line_data, params, wave_subset, mode='Voigt')\n",
    "model_flux = np.exp(-total_tau)\n",
    "\n",
    "# Compute velocity space\n",
    "observed_rest_wavelength = rest_wavelength * (1 + z)\n",
    "velocity = c_km_s * (wavelength_obs - observed_rest_wavelength) / observed_rest_wavelength\n",
    "\n",
    "# Zoom mask for velocity range (-800 km/s to +800 km/s)\n",
    "velocity_zoom = velocity[zoom_mask]\n",
    "\n",
    "# Convert wavelengths of the Voigt profile to velocity\n",
    "velocity_model = c_km_s * (wave_subset - observed_rest_wavelength) / observed_rest_wavelength\n",
    "\n",
    "# Calculate FWHM for each feature\n",
    "centroids = params[2::3]  # Extract every 3rd value starting from index 2\n",
    "doppler_params = params[1::3]  # Extract every 3rd value starting from index 1\n",
    "fwhms = [(2 * np.sqrt(np.log(2)) * b / c_km_s) * l for b, l in zip(doppler_params, centroids)]\n",
    "\n",
    "# Plotting in velocity space\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot flux in velocity space\n",
    "ax.step(velocity_zoom, flux_zoom, where='mid', label='Original Spectrum', color='blue', linewidth=1.5)\n",
    "\n",
    "# Shaded error region\n",
    "ax.fill_between(velocity_zoom, flux_lower, flux_upper, color='green', alpha=0.3, label='Error')\n",
    "\n",
    "# Plot Voigt profile in velocity space\n",
    "ax.step(velocity_model, model_flux, label='Fitted Spectrum (Voigt Profile)', color='red', where='mid', linewidth=3)\n",
    "\n",
    "# Highlight centroids and add FWHM arrows\n",
    "arrowprops = dict(arrowstyle='<->', color='black', lw=1.5)\n",
    "for i, (centroid, fwhm, b) in enumerate(zip(centroids, fwhms, doppler_params)):\n",
    "    centroid_velocity = c_km_s * (centroid - rest_wavelength) / rest_wavelength\n",
    "    if -800 <= centroid_velocity <= 800:  # Include only visible centroids\n",
    "        ax.axvline(centroid_velocity, color=f'C{i}', linestyle='--', label=f'Centroid {i+1}: {centroid_velocity:.1f} km/s')\n",
    "        ax.annotate('', xy=(centroid_velocity - fwhm / 2, 0.75 - i * 0.05), \n",
    "                    xytext=(centroid_velocity + fwhm / 2, 0.75 - i * 0.05), arrowprops=arrowprops)\n",
    "        ax.text(centroid_velocity, 0.77 - i * 0.05, f'b = {b:.1f} km/s', ha='center', fontsize=10)\n",
    "\n",
    "# Highlight reference line for 0 km/s\n",
    "ax.axvline(0, color='purple', linestyle='--', label='OVI 1031.926 Å (0 km/s)', linewidth=2)\n",
    "\n",
    "# Set labels, limits, and grid\n",
    "ax.set_xlabel('Velocity (km/s)', fontsize=14)\n",
    "ax.set_ylabel('Normalized Flux', fontsize=14)\n",
    "ax.set_xlim(-800, 800)\n",
    "ax.set_ylim(0.2, 1.35)\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "# Save and show the plot\n",
    "plt.savefig('OVI_Voigt_Profile_Fit_Velocity_0.1.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# #### Test for a single group\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "import h5py\n",
    "from astropy.table import Table, vstack\n",
    "import os\n",
    "import pygad as pg\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.constants import c as c_km_s\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Constants\n",
    "rest_wavelength = 1031.926  # OVI rest wavelength in Å\n",
    "z = 0.09940180263022191  # Redshift\n",
    "c_km_s = c_km_s / 1e3  # Speed of light in km/s\n",
    "chunk_size = 25  # Interval for saving intermediate results\n",
    "output_dir = \"./results_group_0_err_0.2/\"\n",
    "os.makedirs(output_dir, exist_ok=True)  # Ensure output directory exists\n",
    "\n",
    "# Input file\n",
    "#tng_data_path = \"spectra_TNG50-1_z0.1_n300d2-sample_localized_COS-G130M_OVI_combined.hdf5\"\n",
    "\n",
    "# Initialize results table\n",
    "def initialize_results_table():\n",
    "    return Table(\n",
    "        names=(\n",
    "            'Sightline', 'Species', 'EW(mA)', 'dEW(mA)', 'N', 'dN', 'b', 'db', 'v', \n",
    "            'dv', 'l', 'dl', 'UpLim', 'Sat', 'Chisq'\n",
    "        ),\n",
    "        dtype=['i4', 'S10', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'bool', 'bool', 'f8']\n",
    "    )\n",
    "\n",
    "# Process spectra\n",
    "def process_spectra(group_indices, spectra_file, output_dir, save_interval=25):\n",
    "    # Open HDF5 file\n",
    "    with h5py.File(spectra_file, 'r') as f:\n",
    "        # Extract group-specific data\n",
    "        wavelength_obs = f['wave'][:]\n",
    "        flux_data = f['flux'][group_indices, :]\n",
    "        tau_data = f['tau_OVI_1031'][group_indices, :]\n",
    "\n",
    "        # Initialize results table\n",
    "        results_table = initialize_results_table()\n",
    "\n",
    "        for i, (flux, tau) in tqdm(enumerate(zip(flux_data, tau_data), start=1)):\n",
    "            try:\n",
    "                # Calculate flux from tau\n",
    "                flux_from_tau = np.exp(-tau)\n",
    "\n",
    "                # Generate trident spectrum for processing\n",
    "                with h5py.File('flux_from_tau_temp.h5', 'w') as temp_file:\n",
    "                    temp_file.create_dataset('flux', data=flux_from_tau)\n",
    "                    temp_file.create_dataset('wavelength', data=wavelength_obs)\n",
    "                    temp_file.create_dataset('tau', data=tau)\n",
    "                \n",
    "                sg = trident.load_spectrum('flux_from_tau_temp.h5')\n",
    "                sg.apply_lsf(filename='COS_G130M_1150.txt')\n",
    "                sg.add_gaussian_noise(20)\n",
    "\n",
    "                # Set flux error\n",
    "                flux_err = np.ones_like(flux) * 0.20  # Constant error\n",
    "\n",
    "                # Convert to velocity space\n",
    "                velocity = c_km_s * (wavelength_obs - rest_wavelength * (1 + z)) / (rest_wavelength * (1 + z))\n",
    "                zoom_mask = (velocity >= -800) & (velocity <= 800)\n",
    "                velocity_zoom = velocity[zoom_mask]\n",
    "                flux_zoom = flux[zoom_mask]\n",
    "                flux_err_zoom = flux_err[zoom_mask]\n",
    "\n",
    "                # Fitting pipeline\n",
    "                wave_binned = np.arange(sg.lambda_min.value, sg.lambda_max.value, 0.0112)\n",
    "                flux_binned = np.interp(wave_binned, sg.lambda_field.value, sg.flux_field)\n",
    "                error_binned = np.interp(wave_binned, sg.lambda_field.value, flux_err)\n",
    "                wave_binned /= (1 + z)\n",
    "                vel_binned = c_km_s * (wave_binned - rest_wavelength) / rest_wavelength\n",
    "\n",
    "                min_region_width = 3  # pixels\n",
    "                N_sigma = 1  # 1-sigma detection limit\n",
    "                logN_bounds = [12, 18]\n",
    "                b_bounds = [10, 200]\n",
    "\n",
    "                saturation_flag, output_table, fit = fit_vp_pipeline_new(\n",
    "                    i, 'OVI1031', wave_binned, vel_binned, flux_binned, error_binned, \n",
    "                    z, logN_bounds, b_bounds, min_region_width, N_sigma\n",
    "                )\n",
    "\n",
    "                # Append results\n",
    "                results_table = vstack((results_table, output_table))\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Error processing spectrum {i}: {e}\")\n",
    "                empty_row = Table(\n",
    "                    [[i], ['OVI1031'], [np.nan], [np.nan], [np.nan], [np.nan], [np.nan], [np.nan], \n",
    "                     [np.nan], [np.nan], [np.nan], [np.nan], [False], [False], [np.nan]],\n",
    "                    names=results_table.colnames\n",
    "                )\n",
    "                results_table = vstack((results_table, empty_row))\n",
    "\n",
    "            # Save intermediate results\n",
    "            if i % save_interval == 0:\n",
    "                print(f\"Saving intermediate results at spectrum {i}...\")\n",
    "                results_table.write(\n",
    "                    os.path.join(output_dir, f'intermediate_results_{i}.txt'),\n",
    "                    format='ascii.fixed_width',\n",
    "                    overwrite=True\n",
    "                )\n",
    "\n",
    "        # Save final results\n",
    "        print(\"Saving final results...\")\n",
    "        results_table.write(\n",
    "            os.path.join(output_dir, 'final_results.txt'),\n",
    "            format='ascii.fixed_width',\n",
    "            overwrite=True\n",
    "        )\n",
    "\n",
    "# Define indices for the first group\n",
    "group_indices = range(0,50)\n",
    "\n",
    "# Process the spectra\n",
    "process_spectra(group_indices, tng_data_path, output_dir, save_interval=chunk_size)\n",
    "\n",
    "# %% [markdown]\n",
    "# ### Code for binning, adding noise and then fitting \n",
    "\n",
    "# %% [markdown]\n",
    "# ##### Loading the data example 1 = 50th , example 2 = 500th, example 3 = 750\n",
    "\n",
    "# %%\n",
    "simba_data_path = '/Users/tsingh65/ASU Dropbox/Tanmay Singh/Grad School/MgII_TNG_Project/Primary Project/Trident Codes/SIMBA_IGrM/revised_final/spectra_Simba100_z0.1_n300d2-sample_localized_COS-G130M_OVI_combined.hdf5'\n",
    "\n",
    "tng_data_path = '/Users/tsingh65/ASU Dropbox/Tanmay Singh/Grad School/MgII_TNG_Project/Primary Project/Trident Codes/TNG_50_z_0.1_groups/revised_final/spectra_TNG50-1_z0.1_n300d2-sample_localized_COS-G130M_OVI_combined.hdf5'\n",
    "\n",
    "from scipy.constants import c as c_km_s\n",
    "c_km_s = c_km_s / 1e3  # Speed of light in km/s\n",
    "# Open HDF5 file\n",
    "with h5py.File(tng_data_path, 'r') as f:\n",
    "    # Fetch only the required equivalent width data (first group: indices 0:90000)\n",
    "    chunk_size = 10000  # Chunk size for processing\n",
    "    data_indices = range(0, 90000)  # Range for the first group\n",
    "    eq_widths = []\n",
    "    eq_width_indices = []\n",
    "\n",
    "    # Process in chunks to find the 100th maximum\n",
    "    for start in range(data_indices.start, data_indices.stop, chunk_size):\n",
    "        end = min(start + chunk_size, data_indices.stop)\n",
    "        chunk = f['EW_OVI_1031'][start:end]\n",
    "        eq_widths.extend(chunk)\n",
    "        eq_width_indices.extend(range(start, end))\n",
    "\n",
    "    # Convert to numpy arrays for sorting\n",
    "    eq_widths = np.array(eq_widths)\n",
    "    eq_width_indices = np.array(eq_width_indices)\n",
    "\n",
    "    # Find the 100th maximum equivalent width and its index\n",
    "    sorted_indices = np.argsort(eq_widths)[::-1]  # Sort in descending order\n",
    "    target_index_in_chunk = sorted_indices[200]  # 100th maximum (0-based index)\n",
    "    target_index = eq_width_indices[target_index_in_chunk]\n",
    "\n",
    "    print(f\"100th maximum EW_OVI_1031 value: {eq_widths[target_index_in_chunk]}\")\n",
    "    print(f\"Index of the 100th maximum EW_OVI_1031 in the dataset: {target_index}\")\n",
    "\n",
    "    # Fetch all information for the identified index\n",
    "    result = {\n",
    "        'EW_OVI_1031': f['EW_OVI_1031'][target_index],\n",
    "        'EW_OVI_1037': f['EW_OVI_1037'][target_index],\n",
    "        'flux': f['flux'][target_index, :],\n",
    "        'ray_dir': f['ray_dir'][:],  # ray_dir is not indexed\n",
    "        'ray_pos': f['ray_pos'][target_index, :],\n",
    "        'ray_total_dl': f['ray_total_dl'][()],  # Scalar value\n",
    "        'tau_OVI_1031': f['tau_OVI_1031'][target_index, :],\n",
    "        'tau_OVI_1037': f['tau_OVI_1037'][target_index, :],\n",
    "        'wave': f['wave'][:]\n",
    "    }\n",
    "\n",
    "# %%\n",
    "import h5py\n",
    "import numpy as np\n",
    "from scipy.constants import c as c_km_s\n",
    "\n",
    "\n",
    "# set the random seed for reproducibility = 42\n",
    "np.random.seed(42)\n",
    "\n",
    "# Speed of light in km/s\n",
    "c_km_s = c_km_s / 1e3  \n",
    "\n",
    "# Define file path\n",
    "tng_data_path = '/Users/tsingh65/ASU Dropbox/Tanmay Singh/Grad School/MgII_TNG_Project/Primary Project/Trident Codes/TNG_50_z_0.1_groups/revised_final/spectra_TNG50-1_z0.1_n300d2-sample_localized_COS-G130M_OVI_combined.hdf5'\n",
    "#tng_data_path = '/Users/tsingh65/Downloads/spectra_TNG50-1_z0.1_n300d2-sample_localized_COS-G130M_OVI_6-of-14.hdf5'\n",
    "# Specify the target index directly\n",
    "# 1) 9665\n",
    "# 2) 35710 \n",
    "# for group 6 , index 30 is 6*90000 + 30  = 540030 (can't leave the N=18 absorber)\n",
    "# for group 6 , index 36 is 6*90000 + 36  = 540036 (works good)\n",
    "# for group 6 , index 56 is 6*90000 + 56  = 540056 (no feature but still fitting is being done)\n",
    "# for group 6,  index 68 is 6*90000 + 68  = 540068 (Ok )\n",
    "# for group 6,  index 93 is 6*90000 + 93  = 540093 (OK, leaving the higher N value removes the saturation effect. )\n",
    "# for group 6,  index 129 is 6*90000 + 129  = 540129 ( working)\n",
    "# for group 6, index 45 is 6*90000 + 45 = 540045 (can't leave the N=18 absorber)\n",
    "# for group 6, index 277 is 6*90000 + 277 = 540277 \n",
    "# for group 6, index 778 is 6*90000 + 778 = 540778\n",
    "# for group 6, index 80583 is 6*90000 + 80583 = 620583\n",
    "# for group 6, index 40317 is 6*90000 + 40317 = 580317\n",
    "# for group 1, index 34791 is 1*90000 + 34791 = 124791\n",
    "# for group 7 , index = 2877 is 7*90000 + 2877 = 632877\n",
    "\n",
    "target_index = 656688\n",
    "\n",
    "\n",
    "# Open HDF5 file\n",
    "with h5py.File(tng_data_path, 'r') as f:\n",
    "    # Fetch all information for the identified index\n",
    "    result = {\n",
    "        'EW_OVI_1031': f['EW_OVI_1031'][target_index],\n",
    "        'EW_OVI_1037': f['EW_OVI_1037'][target_index],\n",
    "        'flux': f['flux'][target_index, :],\n",
    "        'ray_dir': f['ray_dir'][:],  # ray_dir is not indexed\n",
    "        'ray_pos': f['ray_pos'][target_index, :],\n",
    "        'ray_total_dl': f['ray_total_dl'][()],  # Scalar value\n",
    "        'tau_OVI_1031': f['tau_OVI_1031'][target_index, :],\n",
    "        'tau_OVI_1037': f['tau_OVI_1037'][target_index, :],\n",
    "        'wave': f['wave'][:]\n",
    "    }\n",
    "\n",
    "# Print the results for the given index\n",
    "print(f\"Results for index {target_index}:\")\n",
    "for key, value in result.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "\n",
    "# %%\n",
    "656688- 7*90000\n",
    "\n",
    "# %%\n",
    "# figure out the coordinate of this sightline, virial radius of the group and centre and then plot the 2D location of the sightline\n",
    "group_7_path = '/Users/tsingh65/ASU Dropbox/Tanmay Singh/Grad School/MgII_TNG_Project/Primary Project/Trident Codes/TNG_50_z_0.1_groups/revised_final/integral_TNG50-1_z0.1_n300d2-sample_localized_OVInumdens_7-of-14.hdf5'\n",
    "\n",
    "# Read the file\n",
    "with h5py.File(group_7_path, 'r') as f:\n",
    "    # Print all keys\n",
    "    keys = list(f.keys())\n",
    "    print(\"Keys in the file:\", keys)\n",
    "    \n",
    "    # Print shapes of each dataset\n",
    "    for key in keys:\n",
    "        print(f\"{key}: {f[key].shape}\")\n",
    "    \n",
    "    # Extract the relevant data for index 3099\n",
    "    index = 26688\n",
    "    ray_pos = f['ray_pos'][index]  # Position of the sightline\n",
    "    ray_dir = f['ray_dir'][:]  # Direction of the rays\n",
    "    ray_total_dl = f['ray_total_dl'][()]  # Total path length\n",
    "\n",
    "    print(\"\\nCoordinates of sightline (ray_pos):\", ray_pos)\n",
    "    print(\"Direction of the sightline (ray_dir):\", ray_dir)\n",
    "    print(\"Total path length (ray_total_dl):\", ray_total_dl)\n",
    "    # calculate and print the i\n",
    "\n",
    "        \n",
    "    \n",
    "        \n",
    "\n",
    "# %%\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# File path\n",
    "tng_data_path = '/Users/tsingh65/ASU Dropbox/Tanmay Singh/Grad School/MgII_TNG_Project/Primary Project/Trident Codes/TNG_50_z_0.1_groups/revised_final/spectra_TNG50-1_z0.1_n300d2-sample_localized_COS-G130M_OVI_combined.hdf5'\n",
    "\n",
    "# Group 7 parameters\n",
    "group_center = np.array([4834.154, 22167.719, 16398.639])  # Group center (x, y, z)\n",
    "r_vir = 384.19003  # Virial radius\n",
    "circle_radius = 1.5 * r_vir  # Circle radius for 1.5 R_vir\n",
    "group_start_index = 90000 * 7\n",
    "group_end_index = 90000 * 8\n",
    "\n",
    "# EW and position extraction\n",
    "sightline_positions = []\n",
    "with h5py.File(tng_data_path, 'r') as f:\n",
    "    # Read data\n",
    "    EW_OVI_1031 = f['EW_OVI_1031'][group_start_index:group_end_index]\n",
    "    ray_pos = f['ray_pos'][group_start_index:group_end_index, :]\n",
    "\n",
    "    # Filter criteria\n",
    "    for i, (EW, pos) in enumerate(zip(EW_OVI_1031, ray_pos)):\n",
    "        # Compute 2D distance (impact parameter) in the x, y plane\n",
    "        distance_2d = np.linalg.norm(pos[:2] - group_center[:2])\n",
    "\n",
    "        # Check if sightline satisfies the criteria\n",
    "        if 0.3 <= EW <= 0.7 and (0.7 * r_vir) <= distance_2d <= (0.9 * r_vir):\n",
    "            sightline_positions.append(pos[:2])  # Only x, y coordinates\n",
    "            print(f\"Sightline {i + group_start_index} meets the criteria.\")\n",
    "            \n",
    "            print(f\"EW_OVI_1031: {EW:.3f}, 2D Distance: {distance_2d:.3f} kpc\")\n",
    "            \n",
    "\n",
    "# Convert positions to NumPy array for easier handling\n",
    "sightline_positions = np.array(sightline_positions)\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Plot group center\n",
    "ax.scatter(group_center[0], group_center[1], color='red', label='Group Center', s=100, zorder=3)\n",
    "\n",
    "# Plot sightlines\n",
    "if sightline_positions.size > 0:\n",
    "    ax.scatter(sightline_positions[:, 0], sightline_positions[:, 1], color='blue', label='Sightlines', s=50, zorder=3)\n",
    "else:\n",
    "    print(\"No sightlines found that match the criteria.\")\n",
    "\n",
    "# Draw a circle for 1.5 R_vir radius\n",
    "circle = plt.Circle(group_center[:2], circle_radius, color='green', fill=False, linestyle='--', label='1.5 R_vir', zorder=2)\n",
    "ax.add_artist(circle)\n",
    "\n",
    "# Customize plot\n",
    "ax.set_xlabel(\"X [kpc]\")\n",
    "ax.set_ylabel(\"Y [kpc]\")\n",
    "ax.set_title(\"2D Location of Sightlines and Group Center\")\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "plt.axis(\"equal\")\n",
    "\n",
    "# Adjust limits for better visualization\n",
    "x_min, x_max = group_center[0] - circle_radius, group_center[0] + circle_radius\n",
    "y_min, y_max = group_center[1] - circle_radius, group_center[1] + circle_radius\n",
    "ax.set_xlim(x_min, x_max)\n",
    "ax.set_ylim(y_min, y_max)\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n",
    "\n",
    "# Print positions of sightlines meeting the criteria\n",
    "print(\"Sightline Positions (x, y):\")\n",
    "for pos in sightline_positions:\n",
    "    print(pos)\n",
    "\n",
    "# %%\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def plot_2d_dataset_with_galaxy_overlays(hdf5_file_path, dataset_name, tng_data_path, galaxy_catalog_path, target_index, group_center, r_vir, output_path):\n",
    "    \"\"\"\n",
    "    Plots a 2D dataset from an HDF5 file and aligns/overlays the group center, 1.5 R_vir circle, galaxies with 25 kpc circles,\n",
    "    and sightline in physical coordinates.\n",
    "\n",
    "    Parameters:\n",
    "        hdf5_file_path (str): Path to the HDF5 file containing the 2D dataset.\n",
    "        dataset_name (str): Name of the 2D dataset to plot.\n",
    "        tng_data_path (str): Path to the HDF5 file containing sightline data.\n",
    "        galaxy_catalog_path (str): Path to the galaxy catalog text file.\n",
    "        target_index (int): Index of the sightline to overlay.\n",
    "        group_center (list or np.array): Coordinates of the group center [x, y, z].\n",
    "        r_vir (float): Virial radius of the group.\n",
    "        output_path (str): Path to save the resulting plot.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the 2D dataset\n",
    "        with h5py.File(hdf5_file_path, 'r') as hdf:\n",
    "            if dataset_name in hdf:\n",
    "                data = hdf[dataset_name][()]\n",
    "                \n",
    "                # Ensure data is 2D\n",
    "                if data.ndim != 2 or data.shape != (3000, 3000):\n",
    "                    print(f\"Dataset '{dataset_name}' is not 2D or not 3000x3000. Found {data.shape} dimensions.\")\n",
    "                    return\n",
    "\n",
    "                # Replace NaN values with a visualization minimum\n",
    "                vmin = 10  # Minimum value for visualization\n",
    "                data = np.nan_to_num(data, nan=vmin)\n",
    "\n",
    "                # Generate physical coordinate grid\n",
    "                pixel_size = (4 * r_vir) / 3000  # Physical distance per pixel\n",
    "                x = np.linspace(-2 * r_vir + group_center[0], 2 * r_vir + group_center[0], 3000)\n",
    "                y = np.linspace(-2 * r_vir + group_center[1], 2 * r_vir + group_center[1], 3000)\n",
    "                xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "                # Load sightline position\n",
    "                with h5py.File(tng_data_path, 'r') as tng_file:\n",
    "                    ray_pos = tng_file['ray_pos'][target_index]  # Extract the sightline position\n",
    "\n",
    "                    # Extract (x, y) components of the sightline and group center\n",
    "                    sightline_2d = ray_pos[:2]\n",
    "                    group_center_2d = group_center[:2]\n",
    "\n",
    "                # Load galaxy catalog and extract positions\n",
    "                galaxy_catalog = pd.read_csv(galaxy_catalog_path, delimiter='|', skipinitialspace=True)\n",
    "                galaxy_catalog.columns = galaxy_catalog.columns.str.strip()  # Clean column names\n",
    "                galaxy_positions = galaxy_catalog[['SubhaloPos_0', 'SubhaloPos_1']].to_numpy()\n",
    "                \n",
    "                # calulcta the impat parameter of the sightline from the group center using x and y coordinates\n",
    "                cen_gx = group_center[0]\n",
    "                cen_gy = group_center[1]\n",
    "                sightline_x = ray_pos[0]\n",
    "                sightline_y = ray_pos[1]\n",
    "                print(f\"Group center x: {cen_gx}, y: {cen_gy}\")\n",
    "                print(f\"Sightline x: {sightline_x}, y: {sightline_y}\")\n",
    "                d_ckpch = np.sqrt((cen_gx - sightline_x)**2 + (cen_gy - sightline_y)**2)\n",
    "                h = 0.6774\n",
    "                z = 0.09940180263022191\n",
    "                d_kpc = d_ckpch / h / (1+z)\n",
    "                print(f\"impact parameter of the sightline from the group center is {d_kpc} kpc\")\n",
    "                \n",
    "\n",
    "                # Create the plot\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                plt.imshow(data, origin='lower', extent=[x.min(), x.max(), y.min(), y.max()],\n",
    "                           cmap='viridis', aspect='auto', vmin=vmin)\n",
    "                plt.colorbar(label='Value')\n",
    "                plt.title(f\"2D Dataset: {dataset_name} with Physical Overlays\")\n",
    "                plt.xlabel(\"X [kpc]\")\n",
    "                plt.ylabel(\"Y [kpc]\")\n",
    "\n",
    "                # Overlay group center\n",
    "                plt.scatter(group_center_2d[0], group_center_2d[1], color='red', label='Group Center', s=100, zorder=3)\n",
    "\n",
    "                # Overlay 1.5 R_vir circle\n",
    "                circle = plt.Circle(group_center_2d, 1.5 * r_vir, color='green', fill=False, linestyle='--', label='1.5 R_vir', zorder=2)\n",
    "                plt.gca().add_artist(circle)\n",
    "\n",
    "                # Overlay sightline\n",
    "                plt.scatter(sightline_2d[0], sightline_2d[1], color='blue', label='Sightline', s=100, zorder=3)\n",
    "\n",
    "                # Overlay galaxies and their 25 kpc circles\n",
    "                for pos in galaxy_positions:\n",
    "                    plt.scatter(pos[0], pos[1], color='orange', label='Galaxy Center', s=50, zorder=3)\n",
    "                    galaxy_circle = plt.Circle(pos, 100, color='orange', fill=False, linestyle='-', zorder=2)\n",
    "                    plt.gca().add_artist(galaxy_circle)\n",
    "\n",
    "                # Add legend and grid\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "\n",
    "                # Save the plot\n",
    "                output_file = os.path.join(output_path, f\"{dataset_name}_2D_plot_with_galaxy_overlays.png\")\n",
    "                plt.savefig(output_file, dpi=600)\n",
    "                print(f\"Plot saved at {output_file}\")\n",
    "\n",
    "                # Show the plot\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(f\"Dataset '{dataset_name}' not found in the HDF5 file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading or plotting dataset: {e}\")\n",
    "\n",
    "\n",
    "# Parameters\n",
    "hdf5_file_path = \"/Users/tsingh65/ASU Dropbox/Tanmay Singh/Grad School/MgII_TNG_Project/Primary Project/Trident Codes/TNG_50_z_0.1_groups/grid_data/grp_15_halo_15_snapshot_91.hdf5\"\n",
    "tng_data_path = \"/Users/tsingh65/ASU Dropbox/Tanmay Singh/Grad School/MgII_TNG_Project/Primary Project/Trident Codes/TNG_50_z_0.1_groups/revised_final/spectra_TNG50-1_z0.1_n300d2-sample_localized_COS-G130M_OVI_combined.hdf5\"\n",
    "galaxy_catalog_path = \"/Users/tsingh65/ASU Dropbox/Tanmay Singh/Synthetic_IGrM_Sightlines/TNG50_fitting_results/galaxy_cats/group_15_galaxy_catalog_converted.txt\"\n",
    "dataset_name = \"grid\"  # Replace with the actual dataset name if different\n",
    "target_index = 656688\n",
    "group_center = np.array([4834.154, 22167.719, 16398.639])  # Group center (x, y, z)\n",
    "r_vir = 384.19003  # Virial radius\n",
    "output_path = \"/Users/tsingh65/ASU Dropbox/Tanmay Singh/Grad School/MgII_TNG_Project/Primary Project/Trident Codes/TNG_50_z_0.1_groups/grid_data\"\n",
    "\n",
    "# Plot with physical coordinate overlays\n",
    "plot_2d_dataset_with_galaxy_overlays(hdf5_file_path, dataset_name, tng_data_path, galaxy_catalog_path, target_index, group_center, r_vir, output_path)\n",
    "\n",
    "# %%\n",
    "def plot_2d_dataset_with_zoom(hdf5_file_path, dataset_name, tng_data_path, target_index, group_center, r_vir, output_path, zoom=True, zoom_radius=1.0):\n",
    "    \"\"\"\n",
    "    Plots a 2D dataset from an HDF5 file and aligns/overlays the group center, 1.5 R_vir circle, and sightline in physical coordinates.\n",
    "    Optionally zooms into the region around the sightline.\n",
    "\n",
    "    Parameters:\n",
    "        hdf5_file_path (str): Path to the HDF5 file containing the 2D dataset.\n",
    "        dataset_name (str): Name of the 2D dataset to plot.\n",
    "        tng_data_path (str): Path to the HDF5 file containing sightline data.\n",
    "        target_index (int): Index of the sightline to overlay.\n",
    "        group_center (list or np.array): Coordinates of the group center [x, y, z].\n",
    "        r_vir (float): Virial radius of the group.\n",
    "        output_path (str): Path to save the resulting plot.\n",
    "        zoom (bool): Whether to zoom in around the sightline position.\n",
    "        zoom_radius (float): Radius of the zoomed-in region in kpc.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load the 2D dataset\n",
    "        with h5py.File(hdf5_file_path, 'r') as hdf:\n",
    "            if dataset_name in hdf:\n",
    "                data = hdf[dataset_name][()]\n",
    "                \n",
    "                # Ensure data is 2D\n",
    "                if data.ndim != 2 or data.shape != (3000, 3000):\n",
    "                    print(f\"Dataset '{dataset_name}' is not 2D or not 3000x3000. Found {data.shape} dimensions.\")\n",
    "                    return\n",
    "\n",
    "                # Replace NaN values with a visualization minimum\n",
    "                vmin = 11  # Minimum value for visualization\n",
    "                data = np.nan_to_num(data, nan=vmin)\n",
    "\n",
    "                # Generate physical coordinate grid\n",
    "                pixel_size = (4 * r_vir) / 3000  # Physical distance per pixel\n",
    "                x = np.linspace(-2 * r_vir + group_center[0], 2 * r_vir + group_center[0], 3000)\n",
    "                y = np.linspace(-2 * r_vir + group_center[1], 2 * r_vir + group_center[1], 3000)\n",
    "                xx, yy = np.meshgrid(x, y)\n",
    "\n",
    "                # Load sightline position\n",
    "                with h5py.File(tng_data_path, 'r') as tng_file:\n",
    "                    ray_pos = tng_file['ray_pos'][target_index]  # Extract the sightline position\n",
    "\n",
    "                    # Extract (x, y) components of the sightline and group center\n",
    "                    sightline_2d = ray_pos[:2]\n",
    "                    group_center_2d = group_center[:2]\n",
    "\n",
    "                # Create the plot\n",
    "                plt.figure(figsize=(10, 8))\n",
    "                plt.imshow(data, origin='lower', extent=[x.min(), x.max(), y.min(), y.max()],\n",
    "                           cmap='magma', aspect='auto', vmin=vmin)\n",
    "                plt.colorbar(label='Value')\n",
    "                plt.title(f\"2D Dataset: {dataset_name} with Physical Overlays\")\n",
    "                plt.xlabel(\"X [kpc]\")\n",
    "                plt.ylabel(\"Y [kpc]\")\n",
    "\n",
    "                # Overlay group center\n",
    "                plt.scatter(group_center_2d[0], group_center_2d[1], color='red', label='Group Center', s=100, zorder=3)\n",
    "\n",
    "                # Overlay 1.5 R_vir circle\n",
    "                circle = plt.Circle(group_center_2d, 1.5 * r_vir, color='green', fill=False, linestyle='--', label='1.5 R_vir', zorder=2)\n",
    "                plt.gca().add_artist(circle)\n",
    "\n",
    "                # Overlay sightline\n",
    "                plt.scatter(sightline_2d[0], sightline_2d[1], color='blue', label='Sightline', s=100, zorder=3)\n",
    "\n",
    "                # Apply zoom if enabled\n",
    "                if zoom:\n",
    "                    plt.xlim(sightline_2d[0] - zoom_radius, sightline_2d[0] + zoom_radius)\n",
    "                    plt.ylim(sightline_2d[1] - zoom_radius, sightline_2d[1] + zoom_radius)\n",
    "\n",
    "                # Add legend and grid\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "\n",
    "                # Save the plot\n",
    "                output_file = os.path.join(output_path, f\"{dataset_name}_2D_plot_with_physical_overlays_zoomed.png\" if zoom else f\"{dataset_name}_2D_plot_with_physical_overlays.png\")\n",
    "                plt.savefig(output_file, dpi=600)\n",
    "                print(f\"Plot saved at {output_file}\")\n",
    "\n",
    "                # Show the plot\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(f\"Dataset '{dataset_name}' not found in the HDF5 file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading or plotting dataset: {e}\")\n",
    "\n",
    "\n",
    "# Parameters\n",
    "hdf5_file_path = \"/Users/tsingh65/ASU Dropbox/Tanmay Singh/Grad School/MgII_TNG_Project/Primary Project/Trident Codes/TNG_50_z_0.1_groups/grid_data/grp_15_halo_15_snapshot_91.hdf5\"\n",
    "tng_data_path = \"/Users/tsingh65/ASU Dropbox/Tanmay Singh/Grad School/MgII_TNG_Project/Primary Project/Trident Codes/TNG_50_z_0.1_groups/revised_final/spectra_TNG50-1_z0.1_n300d2-sample_localized_COS-G130M_OVI_combined.hdf5\"\n",
    "dataset_name = \"grid\"  # Replace with the actual dataset name if different\n",
    "target_index =  656688\n",
    "group_center = np.array([4834.154, 22167.719, 16398.639])  # Group center (x, y, z)\n",
    "r_vir = 384.19003  # Virial radius\n",
    "output_path = \"/Users/tsingh65/ASU Dropbox/Tanmay Singh/Grad School/MgII_TNG_Project/Primary Project/Trident Codes/TNG_50_z_0.1_groups/grid_data\"\n",
    "\n",
    "# Plot with zoom around sightline\n",
    "plot_2d_dataset_with_zoom(hdf5_file_path, dataset_name, tng_data_path, target_index, group_center, r_vir, output_path, zoom=True, zoom_radius=25.0)\n",
    "\n",
    "# %% [markdown]\n",
    "# #### Plot the Raw Spectra\n",
    "# - $$\\Delta \\lambda = 0.00997 \\, \\text{\\AA}$$\n",
    "# \n",
    "\n",
    "# %%\n",
    "# Save the result dictionary\n",
    "\n",
    "# Constants\n",
    "rest_wavelength = 1031.927  # OVI rest wavelength in Å\n",
    "z = 0.09940180263022191                 # Redshift\n",
    "#z = 0.137807\n",
    "\n",
    "#z = 0.13\n",
    "print(\"Data fetched successfully. Example:\", result)\n",
    "\n",
    "# Calculate flux from tau and plot it with tau\n",
    "flux_from_tau = np.exp(-result['tau_OVI_1031'])\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(result['wave'], flux_from_tau, label='Flux (from Tau)')\n",
    "plt.xlabel('Wavelength')\n",
    "plt.ylabel('Flux (from Tau)')\n",
    "plt.title('Flux (from Tau) vs. Wavelength')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# plt.xlim(1170,1190)\n",
    "#plt.xlim(1170,1190)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# plot in the velocity space\n",
    "# Convert to velocity space\n",
    "velocity_orig = c_km_s * (result['wave'] - rest_wavelength * (1 + z)) / (rest_wavelength * (1 + z))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(velocity_orig, flux_from_tau, label='Flux (from Tau)')\n",
    "plt.xlabel('Velocity (km/s)')\n",
    "plt.ylabel('Flux (from Tau)')\n",
    "plt.title('Flux (from Tau) vs. Velocity')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.ylim(0, 1.1)\n",
    "plt.xlim(-800,3600)\n",
    "plt.savefig('Flux_from_Tau_Velocity_spectra_3.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "# import numpy as np\n",
    "# import h5py\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.constants import c as c_km_s\n",
    "\n",
    "# c_km_s = c_km_s / 1e3  # Speed of light in km/s\n",
    "# rest_wavelength = 1031.927  # OVI rest wavelength in Å\n",
    "# z = 0.139706  # Redshift\n",
    "\n",
    "# # Open HDF5 file\n",
    "# with h5py.File(simba_data_path, 'r') as f:\n",
    "#     # Fetch equivalent width data and indices\n",
    "#     data_indices = range(0, 90000)\n",
    "#     eq_widths = []\n",
    "#     eq_width_indices = []\n",
    "#     chunk_size = 10000\n",
    "    \n",
    "#     for start in range(data_indices.start, data_indices.stop, chunk_size):\n",
    "#         end = min(start + chunk_size, data_indices.stop)\n",
    "#         chunk = f['EW_OVI_1031'][start:end]\n",
    "#         eq_widths.extend(chunk)\n",
    "#         eq_width_indices.extend(range(start, end))\n",
    "\n",
    "#     # Convert to numpy arrays and sort\n",
    "#     eq_widths = np.array(eq_widths)\n",
    "#     eq_width_indices = np.array(eq_width_indices)\n",
    "#     sorted_indices = np.argsort(eq_widths)[::-1]  # Sort in descending order\n",
    "    \n",
    "#     # Get top 50 indices\n",
    "#     top_50_indices = eq_width_indices[sorted_indices[:540]]\n",
    "    \n",
    "#     # Fetch and average spectra\n",
    "#     flux_spectra = []\n",
    "#     wave_array = f['wave'][:]  # Same for all spectra\n",
    "    \n",
    "#     for idx in top_50_indices:\n",
    "#         flux_spectra.append(f['flux'][idx, :])\n",
    "    \n",
    "#     flux_spectra = np.array(flux_spectra)\n",
    "#     avg_flux_spectrum = np.mean(flux_spectra, axis=0)\n",
    "    \n",
    "#     # Convert to velocity space\n",
    "#     velocity = c_km_s * (wave_array - rest_wavelength * (1 + z)) / (rest_wavelength * (1 + z))\n",
    "    \n",
    "#     # Plot averaged spectrum in wavelength space\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.plot(wave_array, avg_flux_spectrum, label='Averaged Spectrum')\n",
    "#     plt.xlabel('Wavelength (Å)')\n",
    "#     plt.ylabel('Flux')\n",
    "#     plt.title('Averaged Spectrum in Wavelength Space')\n",
    "#     plt.legend()\n",
    "#     plt.grid()\n",
    "#     plt.xlim(1170, 1190)\n",
    "#     #plt.savefig('Averaged_Spectrum_Wavelength.png', dpi=300)\n",
    "#     plt.show()\n",
    "    \n",
    "#     # Plot averaged spectrum in velocity space\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "#     plt.plot(velocity, avg_flux_spectrum, label='Averaged Spectrum')\n",
    "#     plt.xlabel('Velocity (km/s)')\n",
    "#     plt.ylabel('Flux')\n",
    "#     plt.title('Averaged Spectrum in Velocity Space')\n",
    "#     plt.legend()\n",
    "#     plt.grid()\n",
    "#     plt.ylim(0, 1.1)\n",
    "#     plt.xlim(-800, 3600)\n",
    "#     #plt.savefig('Averaged_Spectrum_Velocity.png', dpi=300)\n",
    "#     plt.show()\n",
    "\n",
    "# %%\n",
    "# # Existing redshift and additional velocity\n",
    "# z = 0.137807\n",
    "# v = 500  # km/s\n",
    "\n",
    "# # Speed of light in km/s\n",
    "# c = c_km_s\n",
    "\n",
    "# # Calculate the new redshift\n",
    "# z_new = (1 + z) * np.sqrt((1 + v / c) / (1 - v / c)) - 1\n",
    "\n",
    "# print(f\"Original redshift (z): {z}\")\n",
    "# print(f\"Additional velocity: {v} km/s\")\n",
    "# print(f\"New redshift (z_new): {z_new:.6f}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# #### First Appying LSF\n",
    "\n",
    "# %%\n",
    "def apply_lsf_to_spectrum(filename,flux):\n",
    "    import pandas as pd\n",
    "    \n",
    "    lsf_data= pd.read_csv(filename, delim_whitespace=True, header=None)\n",
    "    lsf_kernel = lsf_data[1].values\n",
    "\n",
    "    print(f\"SUM of LSF Kernel: {np.sum(lsf_kernel)}\")\n",
    "    \n",
    "    # Convolve the flux with the LSF kernel\n",
    "    from astropy.convolution import convolve\n",
    "    \n",
    "    flux_lsf = convolve(flux, lsf_kernel)\n",
    "    \n",
    "    np.clip(flux_lsf, 0, np.inf, out=flux_lsf)  # Clip negative values to zero\n",
    "    \n",
    "    return flux_lsf\n",
    "\n",
    "# %%\n",
    "# apply LSF to the spectrum and plot \n",
    "flux_lsf = apply_lsf_to_spectrum('COS_G130M_1150.txt',result['flux'])\n",
    "#binned_flux_lsf = apply_lsf_to_spectrum('avg_COS.txt',binned_flux)\n",
    "\n",
    "# Plot the binned flux with LSF applied\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(result['wave'], flux_lsf, label='Flux with LSF')\n",
    "plt.plot(result['wave'], result['flux'], label='Original Flux')\n",
    "plt.xlabel('Wavelength')\n",
    "plt.ylabel('Flux (from Tau)')\n",
    "plt.title('Binned Flux with LSF vs. Wavelength')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# plt.xlim(1120,1160)\n",
    "\n",
    "plt.xlim(1030*(1+z),1035*(1+z))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the original flux as a step plot\n",
    "plt.step(velocity_orig, flux_from_tau, label='Original', where='mid', linewidth=2, alpha=1)\n",
    "\n",
    "# Plot the LSF-applied flux as a step plot\n",
    "plt.step(velocity_orig, flux_lsf, label='LSF Applied', where='mid', linewidth=2, alpha=1)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Velocity (km/s)', fontsize=14)\n",
    "plt.ylabel('Flux (from Tau)', fontsize=14)\n",
    "#plt.title('Flux (from Tau) vs. Velocity', fontsize=16)\n",
    "\n",
    "# Add legend and grid\n",
    "plt.legend(fontsize=12, loc='best')\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Set x-axis limits\n",
    "plt.xlim(-1000, 1000)\n",
    "#plt.savefig('Original_vs_LSF.png', dpi=300)\n",
    "#plt.ylim(0.5,1.5)\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# #### Binning with N pix\n",
    "\n",
    "# %%\n",
    "bin_pixels = 3 # Number of pixels to bin\n",
    "\n",
    "# Bin the flux and wavelength data using the specified number of pixels here.\n",
    "def bin_data(wavelength, flux, bin_pixels):\n",
    "    # Calculate the number of bins\n",
    "    num_bins = len(wavelength) // bin_pixels\n",
    "\n",
    "    # Calculate the new number of pixels\n",
    "    new_num_pixels = num_bins * bin_pixels\n",
    "\n",
    "    # Reshape the flux and wavelength arrays\n",
    "    flux_reshaped = flux[:new_num_pixels].reshape(num_bins, bin_pixels)\n",
    "    wavelength_reshaped = wavelength[:new_num_pixels].reshape(num_bins, bin_pixels)\n",
    "\n",
    "    # Calculate the binned flux and wavelength\n",
    "    binned_flux = np.mean(flux_reshaped, axis=1)\n",
    "    binned_wavelength = np.mean(wavelength_reshaped, axis=1)\n",
    "\n",
    "    return binned_wavelength, binned_flux\n",
    "\n",
    "# Bin the flux and wavelength data\n",
    "binned_wavelength, binned_flux = bin_data(result['wave'], flux_lsf, bin_pixels)\n",
    "\n",
    "# Plot the binned flux\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(binned_wavelength, binned_flux, label='Binned Flux (from Tau)')\n",
    "plt.xlabel('Wavelength')\n",
    "plt.ylabel('Flux (from Tau)')\n",
    "plt.title('Binned Flux (from Tau) vs. Wavelength')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlim(1120,1160)\n",
    "plt.show()\n",
    "\n",
    "# plot in the velocity space\n",
    "velocity = c_km_s * (binned_wavelength - rest_wavelength * (1 + z)) / (rest_wavelength * (1 + z))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(velocity, binned_flux, label='Binned Flux (from Tau)')\n",
    "plt.xlabel('Velocity (km/s)')\n",
    "plt.ylabel('Flux (from Tau)')\n",
    "plt.title('Binned Flux (from Tau) vs. Velocity')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlim(-800,800)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# # overalay unbinned and binned flux inn the velocity space\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.plot(velocity, binned_flux, label='Binned Flux (LSF applied)')\n",
    "# plt.plot(velocity_orig, flux_from_tau, label='Flux')\n",
    "# plt.xlabel('Velocity (km/s)')\n",
    "# plt.ylabel('Flux (from Tau)')\n",
    "# plt.title('Binned Flux vs. Flux')\n",
    "# plt.legend()\n",
    "# plt.grid()\n",
    "# plt.xlim(-800,800)\n",
    "# plt.show()\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# Plot binned flux as a step plot\n",
    "plt.step(velocity, binned_flux, label='LSF + Binning', color='blue', where='mid', linewidth=1.5, alpha=0.8)\n",
    "\n",
    "# Plot unbinned flux as a step plot\n",
    "plt.step(velocity_orig, flux_lsf, label='LSF', color='red', where='mid', linewidth=1.5, alpha=1)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Velocity (km/s)', fontsize=16, labelpad=10)\n",
    "plt.ylabel('Flux (from Tau)', fontsize=16, labelpad=10)\n",
    "#plt.title('Comparison of Binned and Unbinned Flux in Velocity Space', fontsize=18, pad=15)\n",
    "\n",
    "# Customize legend\n",
    "plt.legend(fontsize=14, loc='best', frameon=True, shadow=True)\n",
    "\n",
    "# Add a grid with light style\n",
    "plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "# Set x and y limits\n",
    "plt.xlim(-1000, 1000)  # Corrected xlim to cover the proper range\n",
    "plt.ylim(min(min(binned_flux), min(flux_lsf)) * 0.95, max(max(binned_flux), max(flux_lsf)) * 1.05)\n",
    "\n",
    "# Enhance tick marks\n",
    "plt.tick_params(axis='both', which='major', labelsize=12, direction='in', length=6, width=1.5)\n",
    "\n",
    "# Save the plot as a high-resolution image\n",
    "#plt.savefig('LSF_vs_LSF_binned_spectra_1.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# %% [markdown]\n",
    "# #### Applying Noise , SNR = 10 per resolution element \n",
    "\n",
    "# %%\n",
    "SNR_per_res = 10\n",
    "resolution_pix = 6\n",
    "\n",
    "SNR_per_bin = SNR_per_res/(np.sqrt(resolution_pix/bin_pixels))\n",
    "print(f\"SNR per bin: {SNR_per_bin}\")\n",
    "\n",
    "# %%\n",
    "# make a function to add gaussian noise to the flux with the specified SNR\n",
    "\n",
    "def add_gaussian_noise(flux, SNR):\n",
    "    # Calculate the standard deviation of the noise\n",
    "    seed = 42\n",
    "    np.random.seed(seed)\n",
    "    noise_std = np.mean(flux) / SNR\n",
    "\n",
    "    # Generate Gaussian noise\n",
    "    noise = np.random.normal(0, noise_std, len(flux))\n",
    "\n",
    "    # Add noise to the flux\n",
    "    flux_noisy = flux + noise\n",
    "\n",
    "    return flux_noisy\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "# Add Gaussian noise to the binned flux\n",
    "flux_noisy = add_gaussian_noise(binned_flux, SNR_per_bin)\n",
    "\n",
    "# Plot the noisy flux\n",
    "plt.figure(figsize=(10, 6))\n",
    "# plt.plot(binned_wavelength, flux_noisy, label='Noisy Flux')\n",
    "plt.step(binned_wavelength, flux_noisy, label='Noisy Flux', where='mid', linewidth=1.5, alpha=1)\n",
    "plt.xlabel('Wavelength')\n",
    "plt.ylabel('Flux (from Tau)')\n",
    "plt.title('Noisy Flux vs. Wavelength')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlim(1030*(1+z),1035*(1+z))\n",
    "plt.show()\n",
    "\n",
    "velocity = c_km_s * (binned_wavelength - rest_wavelength * (1 + z)) / (rest_wavelength * (1 + z))\n",
    "print(velocity.shape)\n",
    "# Plot the noisy flux in velocity space\n",
    "plt.figure(figsize=(10, 6))\n",
    "# plt.plot(velocity, flux_noisy, label='Noisy Flux')\n",
    "plt.step(velocity, flux_noisy, label='Noisy Flux', where='mid', linewidth=1.5, alpha=1)\n",
    "plt.xlabel('Velocity (km/s)')\n",
    "plt.ylabel('Flux (from Tau)')\n",
    "plt.title('Noisy Flux vs. Velocity')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "# plt.ylim(0.5,1.5)\n",
    "plt.xlim(-1000,1000)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "# make the noise array with n sigma noise corresponding to the given SNR\n",
    "def make_noise_array(flux, SNR,constant = True):\n",
    "    # Calculate the standard deviation of the noise\n",
    "    if constant == True:\n",
    "        noise = 1/SNR * np.ones_like(flux)\n",
    "    else:\n",
    "        noise_std = np.mean(flux) / SNR\n",
    "\n",
    "        # Generate Gaussian noise\n",
    "        noise = np.random.normal(0, noise_std, len(flux))\n",
    "\n",
    "    return noise\n",
    "\n",
    "# Generate the noise array\n",
    "noise = make_noise_array(flux_noisy, SNR_per_bin,constant=True)\n",
    "print(noise.shape)\n",
    "\n",
    "\n",
    "# %%\n",
    "noise\n",
    "\n",
    "# %%\n",
    "# plot both the flux and the noise array together like this \n",
    "# Convert to velocity space\n",
    "velocity = c_km_s * (binned_wavelength - rest_wavelength * (1 + z)) / (rest_wavelength * (1 + z))\n",
    "print(f\"Velocity: {velocity}\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Create a stepped plot using ax.step\n",
    "ax.step(velocity, flux_noisy, where='mid', label='Flux', color='blue', linewidth=1.5)\n",
    "\n",
    "# Add the shaded error region\n",
    "ax.fill_between(velocity, flux_noisy - noise , flux_noisy + noise, color='green', alpha=0.3, label='Error')\n",
    "\n",
    "# Add vertical and horizontal lines for reference\n",
    "ax.axvline(x=0, color='red', linestyle='--', label=f'OVI {rest_wavelength} Å (0 km/s)', linewidth=2)\n",
    "ax.axhline(y=1, color='gray', linestyle='--', label='Continuum')\n",
    "\n",
    "# # Set x-axis formatter to display floating-point numbers\n",
    "# formatter = FuncFormatter(lambda x, _: f'{x:.0f}')\n",
    "# ax.xaxis.set_major_formatter(formatter)\n",
    "\n",
    "# Set plot labels and title\n",
    "ax.set_xlabel('Velocity (km/s)', fontsize=14)\n",
    "ax.set_ylabel('Normalized Flux', fontsize=14)\n",
    "ax.set_xlim(-800, 800)\n",
    "ax.set_ylim(0.0, 1.35)\n",
    "\n",
    "# Customize ticks and grid\n",
    "ax.tick_params(axis='both', which='major', labelsize=12)\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add legend\n",
    "ax.legend(fontsize=12)\n",
    "\n",
    "# Save and show the plot\n",
    "#plt.savefig('OVI_velocity_space_zoom_shaded_z_013748.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "results_table = Table(\n",
    "    names=(\n",
    "        'Sightline', 'Species', 'EW(mA)', 'dEW(mA)', 'N', 'dN', 'b', 'db', 'v', \n",
    "        'dv', 'l', 'dl', 'UpLim', 'Sat', 'Chisq'\n",
    "    ),\n",
    "    dtype=['i4', 'S10', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'bool', 'bool', 'f8']\n",
    ")\n",
    "\n",
    "# %%\n",
    "\n",
    "\n",
    "try:\n",
    "    pg_ion = 'OVI1031'\n",
    "    wave_binned = binned_wavelength\n",
    "    wave_binned_rest = wave_binned/(1 + z)\n",
    "    vel_binned = wave_to_vel(wave_binned_rest, float(pg.analysis.absorption_spectra.lines[pg_ion]['l'].split()[0]))\n",
    "    flux_binned = flux_noisy\n",
    "    error_binned = noise\n",
    "\n",
    "    min_region_width = 3  # pixels\n",
    "    N_sigma = 3 # 1-sigma detection limit\n",
    "    logN_bounds = [13.5, 18]\n",
    "    b_bounds = [6, 100]\n",
    "    chisq_lim = 1\n",
    "\n",
    "    saturation_flag, output_table,fit,regions = fit_vp_pipeline_new( 1, pg_ion, wave_binned_rest, vel_binned, flux_binned, error_binned, z, logN_bounds, b_bounds, min_region_width, N_sigma,chisq_lim)\n",
    "    results_table = vstack((results_table, output_table))\n",
    "\n",
    "except RuntimeError:\n",
    "    empty_row = Table(\n",
    "        [[ 1], [np.nan], [np.nan], [np.nan], [np.nan], [np.nan], [np.nan], [np.nan], [np.nan], [np.nan], [np.nan], [np.nan], [False], [np.nan], [np.nan]],)\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "EW_to_N('OVI1031', 13.328228594498576*3)\n",
    "\n",
    "# %%\n",
    "results_table = Table(\n",
    "    names=(\n",
    "        'Sightline', 'Species', 'EW(mA)', 'dEW(mA)', 'N', 'dN', 'b', 'db', 'v', \n",
    "        'dv', 'l', 'dl', 'UpLim', 'Sat', 'Chisq'\n",
    "    ),\n",
    "    dtype=['i4', 'S10', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'f8', 'bool', 'bool', 'f8']\n",
    ")\n",
    "\n",
    "\n",
    "results_table = vstack((results_table, output_table))\n",
    "\n",
    "# %%\n",
    "wave_binned\n",
    "\n",
    "# %%\n",
    "binned_wavelength\n",
    "\n",
    "# %%\n",
    "# Convert observed wavelength to rest frame\n",
    "wavelength_rest = wave_binned_rest \n",
    "\n",
    "# Select the range in rest wavelength space\n",
    "zoom_mask = (wavelength_rest >= 1028) & (wavelength_rest <= 1035)\n",
    "\n",
    "# count true values in the zoom mask\n",
    "print(f\"Number of True values in the zoom mask: {np.sum(zoom_mask)}\")\n",
    "\n",
    "# %%\n",
    "# Extract zoomed data in rest wavelength space\n",
    "wavelength_zoom_rest = wavelength_rest[zoom_mask]\n",
    "flux_zoom = flux_noisy[zoom_mask]\n",
    "flux_err_zoom = noise[zoom_mask]\n",
    "flux_upper = flux_zoom + flux_err_zoom\n",
    "flux_lower = flux_zoom - flux_err_zoom\n",
    "\n",
    "# %%\n",
    "\n",
    "fitting_data = {\n",
    "    'N': [17.992483830528826, 13.924630006215876, 14.322969764691424, 13.504412498282178],  # Column densities\n",
    "    'b': [23.354884550850837, 35.102423554192654, 38.87781593059373, 34.809892803010214],  # Doppler parameters\n",
    "    'l': [1032.9528822036423, 1032.6238137252512, 1033.2457246082984, 1033.2870964343672]   # Centroid wavelengths\n",
    "}\n",
    "\n",
    "# fitting_data = {\n",
    "#     'N': [13.627762728567626, 13.83463650854652, 13.907586508371804, 13.506077943128467, 13.710643440946845, 13.680620097917311],  # Column densities\n",
    "#     'b': [34.62001630649476, 99.98341163335535, 21.627720825696773, 8.051624910628453, 21.494323628859412, 29.08035308392944],     # Doppler parameters\n",
    "#     'l': [1032.4140559610435, 1032.879437552414, 1033.0962234038689, 1032.8915702362729, 1033.2501701901726, 1033.6654472160149]  # Centroid wavelengths\n",
    "# }\n",
    "\n",
    "# fitting_data = {\n",
    "#     'N': [18.013234609966627, 14.82061101872063],  # Column densities\n",
    "#     'b': [17.17429070294082, 77.42142875692223],   # Doppler parameters\n",
    "#     'l': [1031.9047774831201, 1031.8703202230272]  # Centroid wavelengths\n",
    "# }\n",
    "\n",
    "# # Define the fitting data\n",
    "# fitting_data = {\n",
    "#     \"Sightline\": [35710, 35710, 35710, 35710, 35710],\n",
    "#     \"Species\": [\"OVI1031\"] * 5,\n",
    "#     \"EW(mA)\": [470.9112527570984, 35.73384219627579, 35.39387096372975, 35.634952771976636, 268.3832591343839],\n",
    "#     \"dEW(mA)\": [float('nan')] * 5,\n",
    "#     \"N\": [18.017747337421095, 13.50709737036714, 13.502423360164864, 13.505772637400014, 14.538282149599882],\n",
    "#     \"dN\": [0.6202466336088821, 1.000000055410929, 1.0000001346476475, 1.0000001337853366, 0.17091492698129115],\n",
    "#     \"b\": [21.120247025492837, 18.98624152919868, 18.982636561271896, 18.98077232285682, 45.46853940331213],\n",
    "#     \"db\": [2.590321983068815, 1.000000112539643, 1.0000000768941977, 1.000000083456931, 16.099769404879623],\n",
    "#     \"v\": [-216.6258488018081, -205.77610784515178, -206.820507882346, -211.88233321068637, -36.17721606646197],\n",
    "#     \"dv\": [2.0939466455272537, 145.26751694740992, 145.26353900131502, 145.27199627587964, 5.742119247646899],\n",
    "#     \"l\": [1031.166354781371, 1031.2037005437185, 1031.2001056269605, 1031.182682379114, 1031.78747484138],\n",
    "#     \"dl\": [0.014415096932742682, 1.0000471322613318, 1.0000197473807777, 1.0000779687461026, 0.03952975866451903],\n",
    "#     \"UpLim\": [False] * 5,\n",
    "#     \"Sat\": [True] * 5,\n",
    "#     \"Chisq\": [2.046075413031284, 2.046075413031284, 2.046075413031284, 2.046075413031284, 0.7835714179362755],\n",
    "# }\n",
    "fitting_data = fit\n",
    "\n",
    "# Generate the Voigt profile for the fitted spectrum\n",
    "line_data = pg.analysis.absorption_spectra.lines['OVI1031']\n",
    "\n",
    "# Generate the params array dynamically\n",
    "params = generate_params(fitting_data)\n",
    "\n",
    "# Voigt profile computation remains the same\n",
    "line_data = pg.analysis.absorption_spectra.lines['OVI1031']\n",
    "wave_subset = wavelength_zoom_rest  # Use the zoomed rest wavelength range\n",
    "total_tau = pg.analysis.vpfit.model_tau(line_data, params, wave_subset, mode='Voigt')\n",
    "model_flux = np.exp(-total_tau)\n",
    "\n",
    "# %%\n",
    "fitting_data\n",
    "\n",
    "# %%\n",
    "# Rest of the code for plotting, FWHM calculation, and annotations remains unchanged.\n",
    "velocity = c_km_s * (wave_binned - rest_wavelength) / (rest_wavelength)\n",
    "# Zoom mask for velocity range (-800 km/s to +800 km/s)\n",
    "velocity_zoom = velocity[zoom_mask]\n",
    "\n",
    "\n",
    "\n",
    "# Calculate FWHM for each feature\n",
    "centroids = params[2::3]  # Extract every 3rd value starting from index 2\n",
    "doppler_params = params[1::3]  # Extract every 3rd value starting from index 1\n",
    "fwhms = [(2 * np.sqrt(np.log(2)) * b / c_km_s) * l for b, l in zip(doppler_params, centroids)]\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Original spectrum\n",
    "ax.plot(wavelength_zoom_rest, flux_zoom, label='Original Spectrum', color='blue')\n",
    "ax.fill_between(wavelength_zoom_rest, flux_lower, flux_upper, color='green', alpha=0.3, label='Error')\n",
    "\n",
    "# Fitted spectrum (Voigt profile)\n",
    "ax.step(wave_subset, model_flux, label='Fitted Spectrum (Voigt Profile)', color='red', where='mid', linewidth=3)\n",
    "\n",
    "# Highlight centroids and add FWHM arrows\n",
    "arrowprops = dict(arrowstyle='<->', color='black', lw=1.5)\n",
    "for i, (centroid, fwhm, b) in enumerate(zip(centroids, fwhms, doppler_params)):\n",
    "    ax.axvline(centroid, color=f'C{i}', linestyle='--', label=f'Centroid {i+1}: {centroid:.2f} Å', linewidth=2)\n",
    "    ax.annotate('', xy=(centroid - fwhm / 2, 0.75 - i * 0.05), \n",
    "                xytext=(centroid + fwhm / 2, 0.75 - i * 0.05), arrowprops=arrowprops)\n",
    "    ax.text(centroid, 0.77 - i * 0.1, f'b = {b:.1f} km/s', ha='center', fontsize=10)\n",
    "\n",
    "# Highlight reference line for OVI in rest wavelength\n",
    "ax.axvline(rest_wavelength, color='purple', linestyle='--', label=f'OVI {rest_wavelength:.2f} Å (Rest Frame)', linewidth=2)\n",
    "\n",
    "# Set labels, limits, and grid\n",
    "ax.set_xlabel('Rest Wavelength (Å)', fontsize=14)\n",
    "ax.set_ylabel('Normalized Flux', fontsize=14)\n",
    "ax.set_xlim(wavelength_zoom_rest.min(), wavelength_zoom_rest.max())\n",
    "ax.set_ylim(0.0, 1.35)\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "#ax.legend(fontsize=12)\n",
    "\n",
    "# Save and show the plot\n",
    "#plt.savefig('OVI_Voigt_Profile_Fit_0.1_err.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "velocity\n",
    "\n",
    "# %%\n",
    "# Constants\n",
    "c_km_s = 299792.458  # Speed of light in km/s\n",
    "\n",
    "# Calculate velocity from wavelength\n",
    "velocity = c_km_s * (wave_binned_rest - rest_wavelength) / rest_wavelength\n",
    "velocity_zoom = velocity[zoom_mask]\n",
    "\n",
    "\n",
    "# Adjust FWHM for velocity space\n",
    "centroid_velocities = c_km_s * (centroids - rest_wavelength) / rest_wavelength\n",
    "fwhms_velocity = [(2 * np.sqrt(np.log(2)) * b) for b in doppler_params]\n",
    "\n",
    "# Plotting\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Original spectrum\n",
    "#ax.plot(velocity_zoom, flux_zoom, label='Original Spectrum', color='blue')\n",
    "# Original spectrum as a step plot\n",
    "ax.step(velocity_zoom, flux_zoom, label='Original Spectrum', color='blue', where='mid', linewidth=2,alpha=0.7)\n",
    "#ax.fill_between(velocity_zoom, flux_lower, flux_upper, color='green', alpha=0.3, label='Error')\n",
    "\n",
    "# Fitted spectrum (Voigt profile)\n",
    "ax.step(velocity[zoom_mask], model_flux, label='Fitted Spectrum (Voigt Profile)', color='red', where='mid', linewidth=3)\n",
    "\n",
    "# Highlight centroids and add FWHM arrows\n",
    "arrowprops = dict(arrowstyle='<->', color='black', lw=1.5)\n",
    "for i, (centroid_vel, fwhm_vel, b) in enumerate(zip(centroid_velocities, fwhms_velocity, doppler_params)):\n",
    "    ax.axvline(centroid_vel, color=f'C{i}', linestyle='--', label=f'Centroid {i+1}: {centroid_vel:.1f} km/s', linewidth=2)\n",
    "    ax.annotate('', xy=(centroid_vel - fwhm_vel / 2, 0.75 - i * 0.05), \n",
    "                xytext=(centroid_vel + fwhm_vel / 2, 0.75 - i * 0.05), arrowprops=arrowprops)\n",
    "    ax.text(centroid_vel, 0.77 - i * 0.1, f'b = {b:.1f} km/s', ha='center', fontsize=10)\n",
    "\n",
    "# Highlight reference line for OVI in velocity space (0 km/s)\n",
    "ax.axvline(0, color='purple', linestyle='--', label=f'OVI {rest_wavelength:.2f} Å (Rest Frame)', linewidth=2)\n",
    "\n",
    "# Set labels, limits, and grid\n",
    "ax.set_xlabel('Velocity (km/s)', fontsize=14)\n",
    "ax.set_ylabel('Normalized Flux', fontsize=14)\n",
    "ax.set_xlim(-800, 800)  # Adjust velocity range as needed\n",
    "ax.set_ylim(0.0, 1.35)\n",
    "ax.grid(True, linestyle='--', alpha=0.7)\n",
    "#ax.legend(fontsize=12)\n",
    "\n",
    "# Save and show the plot\n",
    "#plt.savefig('VP_fit_80583_group_6_sol_dN>2.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Set font styles\n",
    "plt.rc('font', family='Times New Roman')\n",
    "plt.rcParams.update({\n",
    "    'axes.labelsize': 32,\n",
    "    'xtick.labelsize': 30,\n",
    "    'ytick.labelsize': 30,\n",
    "    'legend.fontsize': 30,\n",
    "})\n",
    "\n",
    "c_km_s = 299792.458  # Speed of light in km/s\n",
    "\n",
    "# Fitting results\n",
    "fitting_results = {\n",
    "    'region': np.array([0.]),\n",
    "    'l': np.array([1032.47545845]),\n",
    "    'dl': np.array([0.0799331]),\n",
    "    'b': np.array([73.64487674]),\n",
    "    'db': np.array([0.9999996]),\n",
    "    'N': np.array([14.53968515]),\n",
    "    'dN': np.array([0.17620323]),\n",
    "    'EW': np.array([0.31674129]),\n",
    "    'chisq': np.array([0.79111285])\n",
    "}\n",
    "\n",
    "# Calculate velocity centroids\n",
    "centroid_velocities = c_km_s * (fitting_results['l'] - 1031.92) / 1031.92\n",
    "fwhms_velocity = [(2 * np.sqrt(np.log(2)) * fitting_results['b'][0])]\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(18, 8), gridspec_kw={'width_ratios': [1, 1], 'wspace': 0.25})\n",
    "\n",
    "# Left panel: Galaxy Overlay\n",
    "def plot_galaxy_overlay(ax, hdf5_file_path, dataset_name, tng_data_path, galaxy_catalog_path, target_index, group_center, r_vir):\n",
    "    with h5py.File(hdf5_file_path, 'r') as hdf:\n",
    "        data = hdf[dataset_name][()]\n",
    "        data = np.nan_to_num(data, nan=10)\n",
    "\n",
    "        # Grid extent in R_vir units\n",
    "        x = np.linspace(-2, 2, 3000)\n",
    "        y = np.linspace(-2, 2, 3000)\n",
    "\n",
    "        with h5py.File(tng_data_path, 'r') as tng_file:\n",
    "            ray_pos = tng_file['ray_pos'][target_index]\n",
    "            sightline_2d = (ray_pos[:2] - group_center[:2]) / r_vir\n",
    "\n",
    "        galaxy_catalog = pd.read_csv(galaxy_catalog_path, delimiter='|', skipinitialspace=True)\n",
    "        galaxy_catalog.columns = galaxy_catalog.columns.str.strip()\n",
    "        galaxy_positions = (galaxy_catalog[['SubhaloPos_0', 'SubhaloPos_1']].to_numpy() - group_center[:2]) / r_vir\n",
    "\n",
    "        ax.imshow(data, origin='lower', extent=[x.min(), x.max(), y.min(), y.max()],\n",
    "                  cmap='magma', aspect='equal', vmin=10)\n",
    "        ax.scatter(0, 0, color='crimson', s=50, zorder=3)  # Group center\n",
    "        # Plot the sightline as a blue 'x'\n",
    "        ax.scatter(sightline_2d[0], sightline_2d[1], color='cyan', marker='*', s=250, zorder=3)\n",
    "\n",
    "        # Add a box with the sightline index at the bottom left and an arrow pointing to the sightline location\n",
    "        box_props = dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='snow', alpha=1)\n",
    "        arrowprops = dict(arrowstyle='->', color='white', lw=1.5)\n",
    "\n",
    "        # Annotate with the sightline index enclosed in a box and an arrow\n",
    "        ax.annotate(f\"Sightline {target_index - 90000*7}\",\n",
    "                    xy=(sightline_2d[0], sightline_2d[1]),\n",
    "                    xytext=(-1.2, -1.65),  # Bottom left corner in R_vir units\n",
    "                    fontsize=20, ha='center', va='center', bbox=box_props,\n",
    "                    arrowprops=arrowprops)\n",
    "\n",
    "        # Galaxy circles\n",
    "        for pos in galaxy_positions:\n",
    "            ax.add_artist(plt.Circle(pos, 50 / r_vir, color='aquamarine', fill=False, linestyle='-', zorder=2,linewidth = 1.5))\n",
    "        \n",
    "        # Circle for 1.5 R_vir\n",
    "        ax.add_artist(plt.Circle((0, 0), 1.5, color='white', fill=False, linestyle='solid', linewidth=2, zorder=2))\n",
    "\n",
    "        ax.set_xlabel(\"$X \\, [R_{vir}]$\",labelpad=10,fontsize=32)\n",
    "        ax.set_ylabel(\"$Y \\, [R_{vir}]$\",labelpad=10,fontsize=32)\n",
    "\n",
    "# Parameters for the galaxy overlay\n",
    "hdf5_file_path = \"/Users/tsingh65/ASU Dropbox/Tanmay Singh/Grad School/MgII_TNG_Project/Primary Project/Trident Codes/TNG_50_z_0.1_groups/grid_data/grp_15_halo_15_snapshot_91.hdf5\"\n",
    "tng_data_path = \"/Users/tsingh65/ASU Dropbox/Tanmay Singh/Grad School/MgII_TNG_Project/Primary Project/Trident Codes/TNG_50_z_0.1_groups/revised_final/spectra_TNG50-1_z0.1_n300d2-sample_localized_COS-G130M_OVI_combined.hdf5\"\n",
    "galaxy_catalog_path = \"/Users/tsingh65/ASU Dropbox/Tanmay Singh/Synthetic_IGrM_Sightlines/TNG50_fitting_results/galaxy_cats/group_15_galaxy_catalog_converted.txt\"\n",
    "dataset_name = \"grid\"\n",
    "target_index = 656688\n",
    "group_center = np.array([4834.154, 22167.719, 16398.639])  # Group center\n",
    "r_vir = 384.19003\n",
    "\n",
    "# Left panel: Galaxy overlay\n",
    "plot_galaxy_overlay(axs[0], hdf5_file_path, dataset_name, tng_data_path, galaxy_catalog_path, target_index, group_center, r_vir)\n",
    "\n",
    "# Right panel: Velocity spectrum\n",
    "ax = axs[1]\n",
    "ax.step(velocity_zoom, flux_zoom, label='Original Spectrum', color='blue', where='mid', linewidth=2, alpha=0.7)\n",
    "ax.step(velocity[zoom_mask], model_flux, label='Fitted Spectrum (Voigt Profile)', color='red', where='mid', linewidth=4)\n",
    "\n",
    "# Highlight reference line for OVI in velocity space (0 km/s)\n",
    "ax.axvline(0, color='purple', linestyle='--', linewidth=2)\n",
    "ax.axvline(centroid_velocities[0], color='green', linestyle='--', linewidth=2)\n",
    "ax.axhline(1, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "# Add a text box for \"OVI 1031\" at (500, 0.3)\n",
    "ax.text(500, 0.2, r\"$\\mathrm{OVI \\, 1031}$\", fontsize=36, color='black', ha='center')\n",
    "\n",
    "# Add arrow for the Doppler b-value\n",
    "arrowprops = dict(arrowstyle='<->', color='black', lw=2)\n",
    "b_value_start = centroid_velocities[0] - fwhms_velocity[0] / 2\n",
    "b_value_end = centroid_velocities[0] + fwhms_velocity[0] / 2\n",
    "ax.annotate('', xy=(b_value_start, 0.6), xytext=(b_value_end, 0.6), arrowprops=arrowprops)\n",
    "ax.text(centroid_velocities[0]+220, 0.55, r\"$b = $\" + f\"{fitting_results['b'][0]:.1f} km/s\",\n",
    "        fontsize=18, ha='center', va='bottom', color='black')\n",
    "\n",
    "# Add fitting parameters with proper formatting using mattext\n",
    "textstr = (\n",
    "    f\"$v_{{0}}$: {centroid_velocities[0]:.1f} ± {fitting_results['dl'][0]:.2f} km/s\\n\"\n",
    "    f\"$b$: {fitting_results['b'][0]:.1f} ± {fitting_results['db'][0]:.2f} km/s\\n\"\n",
    "    f\"$N$: {fitting_results['N'][0]:.2f} ± {fitting_results['dN'][0]:.2f}\\n\"\n",
    "    f\"$EW$: {fitting_results['EW'][0]:.3f} Å\\n\"\n",
    "    f\"$\\chi^2$: {fitting_results['chisq'][0]:.3f}\"\n",
    ")\n",
    "\n",
    "# Add text to the plot with center alignment\n",
    "ax.text(\n",
    "    -450, 0.25, textstr,\n",
    "    fontsize=18,\n",
    "    ha='center',\n",
    "    va='center',\n",
    "    alpha=0.9,\n",
    "    color='black',\n",
    "    backgroundcolor='lightgrey',\n",
    "    bbox=dict(facecolor='lightgrey', edgecolor='black', boxstyle='round,pad=0.5'),\n",
    "    \n",
    ")\n",
    "ax.set_xticks(np.arange(-800, 801, 200))\n",
    "ax.set_yticks([0.0, 0.25, 0.5, 0.75, 1.0])\n",
    "# ax.set_xlabel('Velocity (km/s)')\n",
    "ax.set_xlabel(r\"$\\mathrm{Velocity \\, [km s^{-1}]}$\",labelpad=10,fontsize=32)\n",
    "ax.set_ylabel('Normalized Flux')\n",
    "ax.set_xlim(-800, 800)\n",
    "ax.set_ylim(0.0, 1.35)\n",
    "\n",
    "# Adjust layout and save\n",
    "plt.tight_layout()\n",
    "#plt.savefig(\"combined_plot_rvir_velocity_fit.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Set font styles\n",
    "plt.rc('font', family='Times New Roman')\n",
    "plt.rcParams.update({\n",
    "    'axes.labelsize': 32,\n",
    "    'xtick.labelsize': 30,\n",
    "    'ytick.labelsize': 30,\n",
    "    'legend.fontsize': 30,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'axes.linewidth': 2  # Set the width of the box\n",
    "})\n",
    "\n",
    "c_km_s = 299792.458  # Speed of light in km/s\n",
    "\n",
    "# Fitting results\n",
    "fitting_results = {\n",
    "    'region': np.array([0.]),\n",
    "    'l': np.array([1032.47545845]),\n",
    "    'dl': np.array([0.0799331]),\n",
    "    'b': np.array([73.64487674]),\n",
    "    'db': np.array([0.9999996]),\n",
    "    'N': np.array([14.53968515]),\n",
    "    'dN': np.array([0.17620323]),\n",
    "    'EW': np.array([0.31674129]),\n",
    "    'chisq': np.array([0.79111285])\n",
    "}\n",
    "\n",
    "# Calculate velocity centroids\n",
    "centroid_velocities = c_km_s * (fitting_results['l'] - 1031.92) / 1031.92\n",
    "fwhms_velocity = [(2 * np.sqrt(np.log(2)) * fitting_results['b'][0])]\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(18, 6), gridspec_kw={'width_ratios': [1, 2], 'wspace': 0.25})\n",
    "\n",
    "# Left panel: Galaxy Overlay\n",
    "def plot_galaxy_overlay(ax, hdf5_file_path, dataset_name, tng_data_path, galaxy_catalog_path, target_index, group_center, r_vir):\n",
    "    with h5py.File(hdf5_file_path, 'r') as hdf:\n",
    "        data = hdf[dataset_name][()]\n",
    "        data = np.nan_to_num(data, nan=10)\n",
    "\n",
    "        # Grid extent in R_vir units\n",
    "        x = np.linspace(-2, 2, 3000)\n",
    "        y = np.linspace(-2, 2, 3000)\n",
    "\n",
    "        with h5py.File(tng_data_path, 'r') as tng_file:\n",
    "            ray_pos = tng_file['ray_pos'][target_index]\n",
    "            sightline_2d = (ray_pos[:2] - group_center[:2]) / r_vir\n",
    "\n",
    "        galaxy_catalog = pd.read_csv(galaxy_catalog_path, delimiter='|', skipinitialspace=True)\n",
    "        galaxy_catalog.columns = galaxy_catalog.columns.str.strip()\n",
    "        galaxy_positions = (galaxy_catalog[['SubhaloPos_0', 'SubhaloPos_1']].to_numpy() - group_center[:2]) / r_vir\n",
    "\n",
    "        im = ax.imshow(data, origin='lower', extent=[x.min(), x.max(), y.min(), y.max()],\n",
    "                       cmap='magma', aspect='equal', vmin=10)\n",
    "        ax.scatter(0, 0, color='crimson', s=50, zorder=3)  # Group center\n",
    "        ax.scatter(sightline_2d[0], sightline_2d[1], color='cyan', marker='*', s=250, zorder=3)\n",
    "\n",
    "        box_props = dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='snow', alpha=1)\n",
    "        arrowprops = dict(arrowstyle='->', color='white', lw=1.5)\n",
    "        ax.annotate(f\"Sightline {target_index - 90000*7}\",\n",
    "                    xy=(sightline_2d[0], sightline_2d[1]),\n",
    "                    xytext=(-1.2, -1.65),\n",
    "                    fontsize=20, ha='center', va='center', bbox=box_props,\n",
    "                    arrowprops=arrowprops)\n",
    "\n",
    "        for pos in galaxy_positions:\n",
    "            ax.add_artist(plt.Circle(pos, 50 / r_vir, color='aquamarine', fill=False, linestyle='-', zorder=2, linewidth=1.5))\n",
    "        \n",
    "        ax.add_artist(plt.Circle((0, 0), 1.5, color='white', fill=False, linestyle='solid', linewidth=2, zorder=2))\n",
    "\n",
    "        ax.set_xlabel(\"$X \\, [R_{vir}]$\", labelpad=10, fontsize=32)\n",
    "        ax.set_ylabel(\"$Y \\, [R_{vir}]$\", labelpad=10, fontsize=32)\n",
    "\n",
    "hdf5_file_path = \"/Users/tsingh65/ASU Dropbox/Tanmay Singh/Grad School/MgII_TNG_Project/Primary Project/Trident Codes/TNG_50_z_0.1_groups/grid_data/grp_15_halo_15_snapshot_91.hdf5\"\n",
    "tng_data_path = \"/Users/tsingh65/ASU Dropbox/Tanmay Singh/Grad School/MgII_TNG_Project/Primary Project/Trident Codes/TNG_50_z_0.1_groups/revised_final/spectra_TNG50-1_z0.1_n300d2-sample_localized_COS-G130M_OVI_combined.hdf5\"\n",
    "galaxy_catalog_path = \"/Users/tsingh65/ASU Dropbox/Tanmay Singh/Synthetic_IGrM_Sightlines/TNG50_fitting_results/galaxy_cats/group_15_galaxy_catalog_converted.txt\"\n",
    "dataset_name = \"grid\"\n",
    "target_index = 656688\n",
    "group_center = np.array([4834.154, 22167.719, 16398.639])  # Group center\n",
    "r_vir = 384.19003\n",
    "\n",
    "# Left panel: Galaxy overlay\n",
    "plot_galaxy_overlay(axs[0], hdf5_file_path, dataset_name, tng_data_path, galaxy_catalog_path, target_index, group_center, r_vir)\n",
    "\n",
    "# Right panel: Velocity spectrum\n",
    "ax = axs[1]\n",
    "ax.step(velocity_zoom, flux_zoom, label='Original Spectrum', color='blue', where='mid', linewidth=2, alpha=0.7)\n",
    "ax.step(velocity[zoom_mask], model_flux, label='Fitted Spectrum (Voigt Profile)', color='red', where='mid', linewidth=4)\n",
    "\n",
    "ax.axvline(0, color='purple', linestyle='--', linewidth=2)\n",
    "ax.axvline(centroid_velocities[0], color='green', linestyle='--', linewidth=2)\n",
    "ax.axhline(1, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "ax.text(500, 0.2, r\"$\\mathrm{OVI \\, 1031}$\", fontsize=36, color='black', ha='center')\n",
    "\n",
    "arrowprops = dict(arrowstyle='<->', color='black', lw=2)\n",
    "b_value_start = centroid_velocities[0] - fwhms_velocity[0] / 2\n",
    "b_value_end = centroid_velocities[0] + fwhms_velocity[0] / 2\n",
    "ax.annotate('', xy=(b_value_start, 0.6), xytext=(b_value_end, 0.6), arrowprops=arrowprops)\n",
    "ax.text(centroid_velocities[0] + 220, 0.55, r\"$b = $\" + f\"{fitting_results['b'][0]:.1f} km/s\",\n",
    "        fontsize=18, ha='center', va='bottom', color='black')\n",
    "\n",
    "textstr = (\n",
    "    f\"$v_{{0}}$: {centroid_velocities[0]:.1f} ± {fitting_results['dl'][0]:.2f} km/s\\n\"\n",
    "    f\"$b$: {fitting_results['b'][0]:.1f} ± {fitting_results['db'][0]:.2f} km/s\\n\"\n",
    "    f\"$N$: {fitting_results['N'][0]:.2f} ± {fitting_results['dN'][0]:.2f}\\n\"\n",
    "    f\"$EW$: {fitting_results['EW'][0]:.3f} Å\\n\"\n",
    "    f\"$\\chi^2$: {fitting_results['chisq'][0]:.3f}\"\n",
    ")\n",
    "\n",
    "ax.text(-450, 0.25, textstr, fontsize=18, ha='center', va='center', alpha=0.9, color='black', backgroundcolor='lightgrey')\n",
    "\n",
    "# Add minor ticks and customize ticks\n",
    "for ax in axs:\n",
    "    ax.tick_params(which='both', direction='in', width=2)\n",
    "    ax.minorticks_on()\n",
    "    ax.tick_params(which='minor', length=4)\n",
    "    ax.tick_params(which='major', length=8)\n",
    "\n",
    "# Set labels, limits, and layout\n",
    "axs[1].set_xlabel(r\"$\\mathrm{Velocity \\, [km s^{-1}]}$\", labelpad=10, fontsize=32)\n",
    "axs[1].set_ylabel(\"Normalized Flux\")\n",
    "axs[1].set_xlim(-800, 800)\n",
    "axs[1].set_ylim(0.0, 1.35)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Set font styles\n",
    "plt.rc('font', family='Times New Roman')\n",
    "plt.rcParams.update({\n",
    "    'axes.labelsize': 32,\n",
    "    'xtick.labelsize': 30,\n",
    "    'ytick.labelsize': 30,\n",
    "    'legend.fontsize': 30,\n",
    "    'xtick.direction': 'in',\n",
    "    'ytick.direction': 'in',\n",
    "    'axes.linewidth': 2  # Set the width of the box\n",
    "})\n",
    "\n",
    "c_km_s = 299792.458  # Speed of light in km/s\n",
    "\n",
    "# Fitting results\n",
    "fitting_results = {\n",
    "    'region': np.array([0.]),\n",
    "    'l': np.array([1032.47545845]),\n",
    "    'dl': np.array([0.0799331]),\n",
    "    'b': np.array([73.64487674]),\n",
    "    'db': np.array([0.9999996]),\n",
    "    'N': np.array([14.53968515]),\n",
    "    'dN': np.array([0.17620323]),\n",
    "    'EW': np.array([0.31674129]),\n",
    "    'chisq': np.array([0.79111285])\n",
    "}\n",
    "\n",
    "# Calculate velocity centroids\n",
    "centroid_velocities = c_km_s * (fitting_results['l'] - 1031.92) / 1031.92\n",
    "fwhms_velocity = [(2 * np.sqrt(np.log(2)) * fitting_results['b'][0])]\n",
    "\n",
    "# Plotting\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 6), gridspec_kw={'width_ratios': [1, 2], 'wspace': 0.15})\n",
    "\n",
    "# Left panel: Galaxy Overlay\n",
    "def plot_galaxy_overlay(ax, hdf5_file_path, dataset_name, tng_data_path, galaxy_catalog_path, target_index, group_center, r_vir):\n",
    "    with h5py.File(hdf5_file_path, 'r') as hdf:\n",
    "        data = hdf[dataset_name][()]\n",
    "        data = np.nan_to_num(data, nan=10)\n",
    "\n",
    "        # Grid extent in R_vir units\n",
    "        x = np.linspace(-2, 2, 3000)\n",
    "        y = np.linspace(-2, 2, 3000)\n",
    "\n",
    "        with h5py.File(tng_data_path, 'r') as tng_file:\n",
    "            ray_pos = tng_file['ray_pos'][target_index]\n",
    "            sightline_2d = (ray_pos[:2] - group_center[:2]) / r_vir\n",
    "\n",
    "        galaxy_catalog = pd.read_csv(galaxy_catalog_path, delimiter='|', skipinitialspace=True)\n",
    "        galaxy_catalog.columns = galaxy_catalog.columns.str.strip()\n",
    "        galaxy_positions = (galaxy_catalog[['SubhaloPos_0', 'SubhaloPos_1']].to_numpy() - group_center[:2]) / r_vir\n",
    "\n",
    "        im = ax.imshow(data, origin='lower', extent=[x.min(), x.max(), y.min(), y.max()],\n",
    "                       cmap='magma', aspect='equal', vmin=10)\n",
    "        ax.scatter(0, 0, color='crimson', s=50, zorder=3)  # Group center\n",
    "        ax.scatter(sightline_2d[0], sightline_2d[1], color='cyan', marker='*', s=250, zorder=3)\n",
    "\n",
    "        box_props = dict(boxstyle='round,pad=0.3', edgecolor='black', facecolor='snow', alpha=1)\n",
    "        arrowprops = dict(arrowstyle='->', color='white', lw=1.5)\n",
    "        ax.annotate(f\"Sightline {target_index - 90000*7}\",\n",
    "                    xy=(sightline_2d[0], sightline_2d[1]),\n",
    "                    xytext=(-1.1, -1.75),\n",
    "                    fontsize=20, ha='center', va='center', bbox=box_props,\n",
    "                    arrowprops=arrowprops)\n",
    "\n",
    "        for pos in galaxy_positions:\n",
    "            ax.add_artist(plt.Circle(pos, 50 / r_vir, color='aquamarine', fill=False, linestyle='-', zorder=2, linewidth=1.5))\n",
    "        \n",
    "        ax.add_artist(plt.Circle((0, 0), 1.5, color='white', fill=False, linestyle='solid', linewidth=2, zorder=2))\n",
    "\n",
    "        ax.set_xlabel(\"$X \\, [R_{vir}]$\", labelpad=10, fontsize=32)\n",
    "        ax.set_ylabel(\"$Y \\, [R_{vir}]$\", labelpad=10, fontsize=32)\n",
    "\n",
    "        # Add \"ID = 264620\" to the top-left corner in white\n",
    "        ax.text(-1.9, 1.8, \"ID = 264620\", color='white', fontsize=22, ha='left', va='top')\n",
    "\n",
    "        # Add colorbar inside the plot (relative to `imshow` extent)\n",
    "        cbar_ax = ax.inset_axes([0.55, 0.07, 0.4, 0.02])  # [x_start, y_start, width, height] relative to imshow\n",
    "        cbar = fig.colorbar(im, cax=cbar_ax, orientation='horizontal')\n",
    "        cbar.set_label(r\"$\\log$[OVI Column Density](cm$^{-2}$)\", fontsize=12,color='white',labelpad=3)\n",
    "        \n",
    "        # Place tick markers at the top side\n",
    "        cbar.ax.tick_params(labelsize=15, length=8, width=2, direction='in', colors='white', top=True, bottom=False)\n",
    "        cbar.ax.xaxis.set_ticks_position('top')  # Move ticks to the top\n",
    "        cbar.ax.set_xticks([12, 14, 16])  # Set tick positions\n",
    "        cbar.ax.set_xticklabels(['12', '14', '16'])  # Set tick labels\n",
    "        \n",
    "        #cbar.ax.tick_params(labelsize=15, length=0, width=2)\n",
    "        cbar.outline.set_edgecolor('snow')  # Remove colorbar border\n",
    "\n",
    "# Parameters for the galaxy overlay\n",
    "hdf5_file_path = \"/Users/tsingh65/ASU Dropbox/Tanmay Singh/Grad School/MgII_TNG_Project/Primary Project/Trident Codes/TNG_50_z_0.1_groups/grid_data/grp_15_halo_15_snapshot_91.hdf5\"\n",
    "tng_data_path = \"/Users/tsingh65/ASU Dropbox/Tanmay Singh/Grad School/MgII_TNG_Project/Primary Project/Trident Codes/TNG_50_z_0.1_groups/revised_final/spectra_TNG50-1_z0.1_n300d2-sample_localized_COS-G130M_OVI_combined.hdf5\"\n",
    "galaxy_catalog_path = \"/Users/tsingh65/ASU Dropbox/Tanmay Singh/Synthetic_IGrM_Sightlines/TNG50_fitting_results/galaxy_cats/group_15_galaxy_catalog_converted.txt\"\n",
    "dataset_name = \"grid\"\n",
    "target_index = 656688\n",
    "group_center = np.array([4834.154, 22167.719, 16398.639])  # Group center\n",
    "r_vir = 384.19003\n",
    "\n",
    "# Left panel: Galaxy overlay\n",
    "plot_galaxy_overlay(axs[0], hdf5_file_path, dataset_name, tng_data_path, galaxy_catalog_path, target_index, group_center, r_vir)\n",
    "\n",
    "# Right panel: Velocity spectrum\n",
    "ax = axs[1]\n",
    "ax.step(velocity_zoom, flux_zoom, label='Original Spectrum', color='blue', where='mid', linewidth=2, alpha=0.8)\n",
    "ax.step(velocity[zoom_mask], model_flux, label='Fitted Spectrum (Voigt Profile)', color='red', where='mid', linewidth=5)\n",
    "\n",
    "ax.axvline(0, color='purple', linestyle='--', linewidth=2)\n",
    "ax.axvline(centroid_velocities[0], color='black', linestyle='solid', linewidth=2)\n",
    "ax.axhline(1, color='gray', linestyle='--', linewidth=2)\n",
    "\n",
    "ax.text(480, 0.2, r\"$\\mathrm{OVI \\, 1031}$\", fontsize=34, color='black', ha='center',\n",
    "        bbox=dict(facecolor='white', edgecolor='black', boxstyle='round,pad=0.2'))\n",
    "\n",
    "arrowprops = dict(arrowstyle='<->', color='black', lw=2)\n",
    "b_value_start = centroid_velocities[0] - fwhms_velocity[0] / 2\n",
    "b_value_end = centroid_velocities[0] + fwhms_velocity[0] / 2\n",
    "ax.annotate('', xy=(b_value_start, 0.6), xytext=(b_value_end, 0.6), arrowprops=arrowprops)\n",
    "ax.text(centroid_velocities[0] + 220, 0.55, r\"$b = $\" + f\"{fitting_results['b'][0]:.1f} km/s\",\n",
    "        fontsize=18, ha='center', va='bottom', color='black')\n",
    "\n",
    "textstr = (\n",
    "    f\"$v_{{0}}$: {centroid_velocities[0]:.1f} ± {fitting_results['dl'][0]:.2f} km/s\\n\"\n",
    "    f\"$b$: {fitting_results['b'][0]:.1f} ± {fitting_results['db'][0]:.2f} km/s\\n\"\n",
    "    f\"$N$: {fitting_results['N'][0]:.2f} ± {fitting_results['dN'][0]:.2f}\\n\"\n",
    "    f\"$EW$: {fitting_results['EW'][0]:.3f} Å\\n\"\n",
    "    f\"$\\chi^2$: {fitting_results['chisq'][0]:.3f}\"\n",
    ")\n",
    "\n",
    "ax.text(-450, 0.35, textstr, fontsize=20, ha='center', va='center', alpha=0.9, color='black', backgroundcolor='lightgrey')\n",
    "\n",
    "# Add minor ticks and customize ticks\n",
    "for ax in axs:\n",
    "    ax.tick_params(which='both', direction='in', width=2)\n",
    "    ax.tick_params(which='major', length=7, width=2, direction='in', top=True, right=True)\n",
    "    ax.tick_params(which='minor', length=4, width=1.5, direction='in', top=True, right=True)\n",
    "\n",
    "    ax.tick_params(which='minor', length=4)\n",
    "    ax.tick_params(which='major', length=7)\n",
    "    ax.minorticks_on()\n",
    "\n",
    "# Set labels, limits, and layout\n",
    "axs[1].set_xlabel(r\"$\\mathrm{Velocity \\, [km s^{-1}]}$\", labelpad=10, fontsize=32)\n",
    "axs[1].set_ylabel(\"Normalized Flux\")\n",
    "axs[1].set_xlim(-800, 800)\n",
    "# set x labels at , -600, -400, -200, 0, 200, 400, 600, 800\n",
    "axs[1].set_xticks(np.arange(-600, 801, 200))\n",
    "# reduce the font size of the xtickslabels slightly\n",
    "axs[1].set_xticklabels(axs[1].get_xticks(), fontsize=28)\n",
    "\n",
    "axs[1].set_ylim(0.0, 1.35)\n",
    "\n",
    "\n",
    "output_dir = \"/Users/tsingh65/ASU Dropbox/Tanmay Singh/Synthetic_IGrM_Sightlines/TNG50_fitting_results/Plots\"\n",
    "# Save the plot with additional adjustments to avoid clipping\n",
    "plt.savefig(f\"{output_dir}/eg_spectra.pdf\", dpi=400, bbox_inches='tight', pad_inches=0.3)\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "import matplotlib\n",
    "matplotlib.rcdefaults()  # Reset Matplotlib configuration to defaults\n",
    "matplotlib.use('Agg')  # Use the Agg backend for rendering\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', family='DejaVu Sans')  # DejaVu Sans is UTF-8 compatible\n",
    "\n",
    "# %%\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Reset to defaults\n",
    "import matplotlib\n",
    "matplotlib.rcdefaults()\n",
    "\n",
    "# Generate sample data\n",
    "x = np.linspace(0, 10, 100)\n",
    "y = np.sin(x)\n",
    "\n",
    "# Plot\n",
    "plt.plot(x, y, label=\"sin(x)\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Basic Plot\")\n",
    "plt.legend()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig(\"basic_plot_1.png\")\n",
    "plt.show()\n",
    "\n",
    "# %%\n",
    "def EW_to_N(pg_ion,ew_err):\n",
    "\n",
    "    ## Following Draine eq. 9.15\n",
    "\n",
    "    f = float(pg.analysis.absorption_spectra.lines[pg_ion]['f'])\n",
    "    l = float(pg.analysis.absorption_spectra.lines[pg_ion]['l'].split()[0])\n",
    "    N = 1.13e12 * (3 * ew_err * 1.0e-11) / f / (l * 1.0e-8)**2\n",
    "\n",
    "    return np.log10(N)\n",
    "EW_to_N('OVI1031', 13.328228594498576)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
